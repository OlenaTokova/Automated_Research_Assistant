<!DOCTYPE html>
<!-- saved from url=(0089)https://medium.com/@baptisteloquette.entr/langchain-arxiv-tutor-data-loading-c62f55af492d -->
<html lang="en" data-rh="lang"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><title>Data Loading, OCR and Chunking – LangChain Arxiv Tutor | by Baptiste L. | Medium</title><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"><meta data-rh="true" name="theme-color" content="#000000"><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"><meta data-rh="true" property="al:ios:app_name" content="Medium"><meta data-rh="true" property="al:ios:app_store_id" content="828256236"><meta data-rh="true" property="al:android:package" content="com.medium.reader"><meta data-rh="true" property="fb:app_id" content="542599432471018"><meta data-rh="true" property="og:site_name" content="Medium"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2023-07-17T06:46:59.938Z"><meta data-rh="true" name="title" content="Data Loading, OCR and Chunking – LangChain Arxiv Tutor | by Baptiste L. | Medium"><meta data-rh="true" property="og:title" content="LangChain Arxiv Tutor : Data Loading"><meta data-rh="true" property="al:android:url" content="medium://p/c62f55af492d"><meta data-rh="true" property="al:ios:url" content="medium://p/c62f55af492d"><meta data-rh="true" property="al:android:app_name" content="Medium"><meta data-rh="true" name="description" content="This Series of Articles covers the usage of LangChain, to create an Arxiv Tutor. That will allow anyone to interact in different ways with the papers to enhance engagement, generate tests, … I…"><meta data-rh="true" property="og:description" content="This Series of Articles covers the usage of LangChain, to create an Arxiv Tutor. That will allow anyone to interact in different ways with…"><meta data-rh="true" property="og:url" content="https://medium.com/@baptisteloquette.entr/langchain-arxiv-tutor-data-loading-c62f55af492d"><meta data-rh="true" property="al:web:url" content="https://medium.com/@baptisteloquette.entr/langchain-arxiv-tutor-data-loading-c62f55af492d"><meta data-rh="true" property="og:image" content="https://miro.medium.com/v2/resize:fit:512/1*UpAKNhJYTpaQ4eWJKzWeDQ.png"><meta data-rh="true" property="article:author" content="https://medium.com/@baptisteloquette.entr"><meta data-rh="true" name="author" content="Baptiste L."><meta data-rh="true" name="robots" content="index,follow,max-image-preview:large"><meta data-rh="true" name="referrer" content="unsafe-url"><meta data-rh="true" property="twitter:title" content="LangChain Arxiv Tutor : Data Loading"><meta data-rh="true" name="twitter:site" content="@Medium"><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/c62f55af492d"><meta data-rh="true" property="twitter:description" content="This Series of Articles covers the usage of LangChain, to create an Arxiv Tutor. That will allow anyone to interact in different ways with…"><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/v2/resize:fit:512/1*UpAKNhJYTpaQ4eWJKzWeDQ.png"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" name="twitter:label1" content="Reading time"><meta data-rh="true" name="twitter:data1" content="8 min read"><link data-rh="true" rel="icon" href="https://miro.medium.com/v2/1*m-R_BkNf1Qjr1YbyOIJY2w.png"><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://medium.com/osd.xml"><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/v2/resize:fill:152:152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/v2/resize:fill:120:120/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/v2/resize:fill:76:76/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/v2/resize:fill:60:60/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/Medium-Avatar-500x500.svg" color="#171717"><link data-rh="true" rel="preconnect" href="https://glyph.medium.com/" crossorigin=""><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/unbound.css"><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/unbound.css"><link data-rh="true" rel="author" href="https://medium.com/@baptisteloquette.entr"><link data-rh="true" rel="canonical" href="https://medium.com/@baptisteloquette.entr/langchain-arxiv-tutor-data-loading-c62f55af492d"><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/c62f55af492d"><script async="" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/branch-latest.min.js.download"></script><script data-rh="true" type="application/ld+json">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:1200\u002F1*UpAKNhJYTpaQ4eWJKzWeDQ.png"],"url":"https:\u002F\u002Fmedium.com\u002F@baptisteloquette.entr\u002Flangchain-arxiv-tutor-data-loading-c62f55af492d","dateCreated":"2023-07-06T12:28:50.842Z","datePublished":"2023-07-06T12:28:50.842Z","dateModified":"2023-08-18T20:39:46.769Z","headline":"Data Loading, OCR and Chunking – LangChain Arxiv Tutor","name":"Data Loading, OCR and Chunking – LangChain Arxiv Tutor","description":"This Series of Articles covers the usage of LangChain, to create an Arxiv Tutor. That will allow anyone to interact in different ways with the papers to enhance engagement, generate tests, … I…","identifier":"c62f55af492d","author":{"@type":"Person","name":"Baptiste L.","url":"https:\u002F\u002Fmedium.com\u002F@baptisteloquette.entr"},"creator":["Baptiste L."],"publisher":{"@type":"Organization","name":"Medium","url":"https:\u002F\u002Fmedium.com\u002F","logo":{"@type":"ImageObject","width":308,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:616\u002F1*OMF3fSqH8t4xBJ9-6oZDZw.png"}},"mainEntityOfPage":"https:\u002F\u002Fmedium.com\u002F@baptisteloquette.entr\u002Flangchain-arxiv-tutor-data-loading-c62f55af492d"}</script><style type="text/css" data-fela-rehydration="536" data-fela-type="STATIC">html{box-sizing:border-box;-webkit-text-size-adjust:100%}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden="true"]{visibility:hidden;pointer-events:none}
/*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/.hljs {background: #fff;color: black;
}/* Gray DOCTYPE selectors like WebKit */
.xml .hljs-meta {color: #c0c0c0;
}.hljs-comment,
.hljs-quote {color: #007400;
}.hljs-tag,
.hljs-attribute,
.hljs-keyword,
.hljs-selector-tag,
.hljs-literal,
.hljs-name {color: #aa0d91;
}.hljs-variable,
.hljs-template-variable {color: #3F6E74;
}.hljs-code,
.hljs-string,
.hljs-meta .hljs-string {color: #c41a16;
}.hljs-regexp,
.hljs-link {color: #0E0EFF;
}.hljs-title,
.hljs-symbol,
.hljs-bullet,
.hljs-number {color: #1c00cf;
}.hljs-section,
.hljs-meta {color: #643820;
}.hljs-title.class_,
.hljs-class .hljs-title,
.hljs-type,
.hljs-built_in,
.hljs-params {color: #5c2699;
}.hljs-attr {color: #836C28;
}.hljs-subst {color: #000;
}.hljs-formula {background-color: #eee;font-style: italic;
}.hljs-addition {background-color: #baeeba;
}.hljs-deletion {background-color: #ffc8bd;
}.hljs-selector-id,
.hljs-selector-class {color: #9b703f;
}.hljs-doctag,
.hljs-strong {font-weight: bold;
}.hljs-emphasis {font-style: italic;
}
</style><style type="text/css" data-fela-rehydration="536" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}</style><style type="text/css" data-fela-rehydration="536" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{display:block}.m{position:sticky}.n{top:0}.o{z-index:500}.p{padding:0 24px}.q{align-items:center}.r{border-bottom:solid 1px #F2F2F2}.y{height:41px}.z{line-height:20px}.ab{display:flex}.ac{height:57px}.ae{flex:1 0 auto}.af{color:inherit}.ag{fill:inherit}.ah{font-size:inherit}.ai{border:inherit}.aj{font-family:inherit}.ak{letter-spacing:inherit}.al{font-weight:inherit}.am{padding:0}.an{margin:0}.ao{cursor:pointer}.ap:disabled{cursor:not-allowed}.aq:disabled{color:#6B6B6B}.ar:disabled{fill:#6B6B6B}.au{fill:rgba(0, 0, 0, 1)}.av{height:22px}.aw{margin-left:16px}.ax{border:none}.ay{border-radius:20px}.az{width:240px}.ba{background:#F9F9F9}.bb path{fill:#6B6B6B}.bd{outline:none}.be{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bf{font-size:14px}.bg{width:100%}.bh{padding:10px 20px 10px 0}.bi{background-color:transparent}.bj{color:#242424}.bk::placeholder{color:#6B6B6B}.bl{display:inline-block}.bm{margin-left:12px}.bn{margin-right:12px}.bo{border-radius:4px}.bp{margin-left:24px}.bq{height:24px}.bw{background-color:#F9F9F9}.bx{border-radius:50%}.by{height:32px}.bz{width:32px}.ca{justify-content:center}.cg{max-width:680px}.ch{min-width:0}.ci{animation:k1 1.2s ease-in-out infinite}.cj{height:100vh}.ck{margin-bottom:16px}.cl{margin-top:48px}.cm{align-items:flex-start}.cn{flex-direction:column}.co{justify-content:space-between}.cp{margin-bottom:24px}.cv{width:80%}.cw{background-color:#F2F2F2}.dc{height:44px}.dd{width:44px}.de{margin:auto 0}.df{margin-bottom:4px}.dg{height:16px}.dh{width:120px}.di{width:80px}.do{margin-bottom:8px}.dp{width:96%}.dq{width:98%}.dr{width:81%}.ds{margin-left:8px}.dt{color:#6B6B6B}.du{font-size:13px}.dv{height:100%}.eo{color:#FFFFFF}.ep{fill:#FFFFFF}.eq{background:#1A8917}.er{border-color:#1A8917}.ev:disabled{cursor:inherit !important}.ew:disabled{opacity:0.3}.ex:disabled:hover{background:#1A8917}.ey:disabled:hover{border-color:#1A8917}.ez{border-radius:99em}.fa{border-width:1px}.fb{border-style:solid}.fc{box-sizing:border-box}.fd{text-decoration:none}.fe{text-align:center}.fh{margin-right:32px}.fi{position:relative}.fj{fill:#6B6B6B}.fm{background:transparent}.fn svg{margin-left:4px}.fo svg{fill:#6B6B6B}.fq{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.fr{position:absolute}.fy{margin:0 24px}.gc{background:rgba(255, 255, 255, 1)}.gd{border:1px solid #F2F2F2}.ge{box-shadow:0 1px 4px #F2F2F2}.gf{max-height:100vh}.gg{overflow-y:auto}.gh{left:0}.gi{top:calc(100vh + 100px)}.gj{bottom:calc(100vh + 100px)}.gk{width:10px}.gl{pointer-events:none}.gm{word-break:break-word}.gn{word-wrap:break-word}.go:after{display:block}.gp:after{content:""}.gq:after{clear:both}.gr{margin-left:auto}.gs{margin-right:auto}.gt{max-width:512px}.gz{clear:both}.ha{max-width:100%}.hb{height:auto}.hc{line-height:1.23}.hd{letter-spacing:0}.he{font-style:normal}.hf{font-weight:700}.if{@media all and (max-width: 551.98px):8px}.ig{@media all and (min-width: 552px) and (max-width: 727.98px):8px}.ih{@media all and (min-width: 728px) and (max-width: 903.98px):16px}.ii{@media all and (min-width: 904px) and (max-width: 1079.98px):16px}.ij{@media all and (min-width: 1080px):16px}.ip{align-items:baseline}.iq{width:48px}.ir{height:48px}.is{border:2px solid rgba(255, 255, 255, 1)}.it{z-index:0}.iu{box-shadow:none}.iv{border:1px solid rgba(0, 0, 0, 0.05)}.iw{margin-bottom:2px}.ix{flex-wrap:nowrap}.iy{font-size:16px}.iz{line-height:24px}.jb{margin:0 8px}.jc{display:inline}.jd{color:#1A8917}.je{fill:#1A8917}.jh{flex:0 0 auto}.jk{flex-wrap:wrap}.jl{padding-left:8px}.jm{padding-right:8px}.kn> *{flex-shrink:0}.ko{overflow-x:scroll}.kp::-webkit-scrollbar{display:none}.kq{scrollbar-width:none}.kr{-ms-overflow-style:none}.ks{width:74px}.kt{flex-direction:row}.ku{margin-right:4px}.kx{-webkit-user-select:none}.ky{border:0}.kz{fill:rgba(117, 117, 117, 1)}.lc{outline:0}.ld{user-select:none}.le> svg{pointer-events:none}.ln{cursor:progress}.lo{margin-left:4px}.lp{margin-top:0px}.lq{opacity:1}.lr{padding:4px 0}.lu{width:16px}.lw{display:inline-flex}.mc{padding:8px 2px}.md svg{color:#6B6B6B}.mu{line-height:1.58}.mv{letter-spacing:-0.004em}.mw{font-family:source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif}.nr{margin-bottom:-0.46em}.ns{font-style:italic}.nt{line-height:1.12}.nu{letter-spacing:-0.022em}.nv{font-weight:600}.oq{margin-bottom:-0.28em}.pb{overflow-x:auto}.pc{font-family:source-code-pro, Menlo, Monaco, "Courier New", Courier, monospace}.pd{padding:32px}.pe{border:1px solid #E5E5E5}.pf{line-height:1.4}.pg{margin-top:-0.2em}.ph{margin-bottom:-0.2em}.pi{white-space:pre}.pj{min-width:fit-content}.pk{padding:2px 4px}.pl{font-size:75%}.pm> strong{font-family:inherit}.ps{box-shadow:inset 0 0 0 1px #F2F2F2}.pt{padding:0px}.pu{padding:16px 20px}.pv{flex:1 1 auto}.px{overflow:hidden}.py{max-height:40px}.pz{text-overflow:ellipsis}.qa{display:-webkit-box}.qb{-webkit-line-clamp:2}.qc{-webkit-box-orient:vertical}.qe{margin-top:8px}.qf{margin-top:12px}.qg{width:160px}.qh{background-image:url(https://miro.medium.com/v2/da:true/resize:fit:320/0*tALmt-8ZHIEZSzqL)}.qi{background-origin:border-box}.qj{background-size:cover}.qk{height:167px}.ql{background-position:50% 50%}.qm{list-style-type:decimal}.qn{margin-left:30px}.qo{padding-left:0px}.qp{margin-top:16px}.qq{max-width:1700px}.qs{cursor:zoom-in}.qt{z-index:auto}.ra{margin-top:32px}.rb{margin-bottom:14px}.rc{padding-top:24px}.rd{padding-bottom:10px}.re{background-color:#000000}.rf{height:3px}.rg{width:3px}.rh{margin-right:20px}.ri{list-style-type:disc}.rj{margin-bottom:26px}.rk{margin-top:6px}.rl{margin-right:8px}.rm{padding:8px 16px}.rn{border-radius:100px}.ro{transition:background 300ms ease}.rq{white-space:nowrap}.rr{border-top:none}.rx{height:52px}.ry{max-height:52px}.rz{box-sizing:content-box}.sa{position:static}.sb{z-index:1}.sd{max-width:155px}.so{align-items:flex-end}.sp{width:76px}.sq{height:76px}.sr{border:2px solid #F9F9F9}.ss{height:72px}.st{width:72px}.su{width:auto}.sv{stroke:#F2F2F2}.sw{height:36px}.sx{width:36px}.sy{color:#F2F2F2}.sz{fill:#F2F2F2}.ta{background:#F2F2F2}.tb{border-color:#F2F2F2}.th{font-weight:500}.ti{font-size:24px}.tj{line-height:30px}.tk{letter-spacing:-0.016em}.tl{height:0px}.tm{border-bottom:solid 1px #E5E5E5}.tn{margin-top:72px}.to{padding:24px 0}.tp{margin-bottom:0px}.tq{margin-right:16px}.as:hover:not(:disabled){color:rgba(25, 25, 25, 1)}.at:hover:not(:disabled){fill:rgba(25, 25, 25, 1)}.es:hover{background:#156D12}.et:hover{border-color:#156D12}.eu:hover{cursor:pointer}.fk:hover{color:#242424}.fl:hover{fill:#242424}.fp:hover svg{fill:#242424}.fs:hover{background-color:rgba(0, 0, 0, 0.1)}.ja:hover{text-decoration:underline}.jf:hover:not(:disabled){color:#156D12}.jg:hover:not(:disabled){fill:#156D12}.lb:hover{fill:rgba(8, 8, 8, 1)}.ls:hover{fill:#000000}.lt:hover p{color:#000000}.lv:hover{color:#000000}.me:hover svg{color:#000000}.rp:hover{background-color:#F2F2F2}.tc:hover{background:#F2F2F2}.td:hover{border-color:#F2F2F2}.te:hover{cursor:wait}.tf:hover{color:#F2F2F2}.tg:hover{fill:#F2F2F2}.bc:focus-within path{fill:#242424}.la:focus{fill:rgba(8, 8, 8, 1)}.mf:focus svg{color:#000000}.qu:focus{transform:scale(1.01)}.lf:active{border-style:none}</style><style type="text/css" data-fela-rehydration="536" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.bv{width:64px}.cf{margin:0 64px}.cu{height:48px}.db{margin-bottom:52px}.dn{margin-bottom:48px}.ee{font-size:14px}.ef{line-height:20px}.el{font-size:13px}.em{padding:5px 12px}.fg{display:flex}.fx{margin-bottom:68px}.gb{max-width:680px}.gy{margin-top:40px}.ia{font-size:42px}.ib{margin-top:1em}.ic{margin-bottom:32px}.id{line-height:52px}.ie{letter-spacing:-0.011em}.io{align-items:center}.jz{border-top:solid 1px #F2F2F2}.ka{border-bottom:solid 1px #F2F2F2}.kb{margin:32px 0 0}.kc{padding:3px 8px}.kl> *{margin-right:24px}.km> :last-child{margin-right:0}.lm{margin-top:0px}.mb{margin:0}.nn{font-size:20px}.no{margin-top:2.14em}.np{line-height:32px}.nq{letter-spacing:-0.003em}.om{font-size:24px}.on{margin-top:1.95em}.oo{line-height:30px}.op{letter-spacing:-0.016em}.ov{margin-top:0.94em}.pa{margin-top:56px}.pr{margin-top:32px}.qz{margin-top:1.14em}.rw{margin-bottom:88px}.si{display:inline-block}.sn{padding-top:72px}</style><style type="text/css" data-fela-rehydration="536" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.ll{margin-top:0px}.sh{display:inline-block}</style><style type="text/css" data-fela-rehydration="536" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.lk{margin-top:0px}.sg{display:inline-block}</style><style type="text/css" data-fela-rehydration="536" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.li{margin-top:0px}.lj{margin-right:0px}.pw{padding:10px 12px 10px}.sf{display:inline-block}</style><style type="text/css" data-fela-rehydration="536" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.s{display:flex}.t{justify-content:space-between}.br{width:24px}.cb{margin:0 24px}.cq{height:40px}.cx{margin-bottom:44px}.dj{margin-bottom:32px}.dw{font-size:13px}.dx{line-height:20px}.eg{padding:0px 8px 1px}.ft{margin-bottom:4px}.gu{margin-top:32px}.hg{font-size:32px}.hh{margin-top:1.01em}.hi{margin-bottom:24px}.hj{line-height:38px}.hk{letter-spacing:-0.014em}.ik{align-items:flex-start}.ji{flex-direction:column}.jn{margin:24px -24px 0}.jo{padding:0}.kd> *{margin-right:8px}.ke> :last-child{margin-right:24px}.kv{margin-left:0px}.lg{margin-top:0px}.lh{margin-right:0px}.lx{margin:0}.mg{border:1px solid #F2F2F2}.mh{border-radius:99em}.mi{padding:0px 16px 0px 12px}.mj{height:38px}.mk{align-items:center}.mm svg{margin-right:8px}.mx{font-size:18px}.my{margin-top:1.56em}.mz{line-height:28px}.na{letter-spacing:-0.003em}.nw{font-size:20px}.nx{margin-top:1.2em}.ny{line-height:24px}.nz{letter-spacing:0}.or{margin-top:0.67em}.ow{margin-top:40px}.pn{margin-top:24px}.qv{margin-top:1.34em}.rs{margin-bottom:80px}.se{display:inline-block}.sj{padding-top:48px}.ml:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="536" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.bu{width:64px}.ce{margin:0 64px}.ct{height:48px}.da{margin-bottom:52px}.dm{margin-bottom:48px}.ec{font-size:14px}.ed{line-height:20px}.ej{font-size:13px}.ek{padding:5px 12px}.ff{display:flex}.fw{margin-bottom:68px}.ga{max-width:680px}.gx{margin-top:40px}.hv{font-size:42px}.hw{margin-top:1em}.hx{margin-bottom:32px}.hy{line-height:52px}.hz{letter-spacing:-0.011em}.in{align-items:center}.jv{border-top:solid 1px #F2F2F2}.jw{border-bottom:solid 1px #F2F2F2}.jx{margin:32px 0 0}.jy{padding:3px 8px}.kj> *{margin-right:24px}.kk> :last-child{margin-right:0}.ma{margin:0}.nj{font-size:20px}.nk{margin-top:2.14em}.nl{line-height:32px}.nm{letter-spacing:-0.003em}.oi{font-size:24px}.oj{margin-top:1.95em}.ok{line-height:30px}.ol{letter-spacing:-0.016em}.ou{margin-top:0.94em}.oz{margin-top:56px}.pq{margin-top:32px}.qy{margin-top:1.14em}.rv{margin-bottom:88px}.sm{padding-top:72px}</style><style type="text/css" data-fela-rehydration="536" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.w{display:flex}.x{justify-content:space-between}.bt{width:64px}.cd{margin:0 48px}.cs{height:48px}.cz{margin-bottom:52px}.dl{margin-bottom:48px}.ea{font-size:13px}.eb{line-height:20px}.ei{padding:0px 8px 1px}.fv{margin-bottom:68px}.fz{max-width:680px}.gw{margin-top:40px}.hq{font-size:42px}.hr{margin-top:1em}.hs{margin-bottom:32px}.ht{line-height:52px}.hu{letter-spacing:-0.011em}.im{align-items:center}.jr{border-top:solid 1px #F2F2F2}.js{border-bottom:solid 1px #F2F2F2}.jt{margin:32px 0 0}.ju{padding:3px 8px}.kh> *{margin-right:24px}.ki> :last-child{margin-right:0}.lz{margin:0}.nf{font-size:20px}.ng{margin-top:2.14em}.nh{line-height:32px}.ni{letter-spacing:-0.003em}.oe{font-size:24px}.of{margin-top:1.95em}.og{line-height:30px}.oh{letter-spacing:-0.016em}.ot{margin-top:0.94em}.oy{margin-top:56px}.pp{margin-top:32px}.qx{margin-top:1.14em}.ru{margin-bottom:88px}.sl{padding-top:72px}</style><style type="text/css" data-fela-rehydration="536" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.u{display:flex}.v{justify-content:space-between}.bs{width:24px}.cc{margin:0 24px}.cr{height:40px}.cy{margin-bottom:44px}.dk{margin-bottom:32px}.dy{font-size:13px}.dz{line-height:20px}.eh{padding:0px 8px 1px}.fu{margin-bottom:4px}.gv{margin-top:32px}.hl{font-size:32px}.hm{margin-top:1.01em}.hn{margin-bottom:24px}.ho{line-height:38px}.hp{letter-spacing:-0.014em}.il{align-items:flex-start}.jj{flex-direction:column}.jp{margin:24px 0 0}.jq{padding:0}.kf> *{margin-right:8px}.kg> :last-child{margin-right:8px}.kw{margin-left:0px}.ly{margin:0}.mn{border:1px solid #F2F2F2}.mo{border-radius:99em}.mp{padding:0px 16px 0px 12px}.mq{height:38px}.mr{align-items:center}.mt svg{margin-right:8px}.nb{font-size:18px}.nc{margin-top:1.56em}.nd{line-height:28px}.ne{letter-spacing:-0.003em}.oa{font-size:20px}.ob{margin-top:1.2em}.oc{line-height:24px}.od{letter-spacing:0}.os{margin-top:0.67em}.ox{margin-top:40px}.po{margin-top:24px}.qw{margin-top:1.34em}.rt{margin-bottom:80px}.sk{padding-top:48px}.ms:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="536" data-fela-type="RULE" media="print">.sc{display:none}</style><style type="text/css" data-fela-rehydration="536" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.qd{max-height:none}</style><style type="text/css" data-fela-rehydration="536" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.qr{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style><script async="true" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/js" data-rh="true"></script><script data-rh="true">window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());

            gtag('config', 'G-7JY7T788PK');</script><script type="text/javascript" data-rh="true">(function(b,r,a,n,c,h,_,s,d,k){if(!b[n]||!b[n]._q){for(;s<_.length;)c(h,_[s++]);d=r.createElement(a);d.async=1;d.src="https://cdn.branch.io/branch-latest.min.js";k=r.getElementsByTagName(a)[0];k.parentNode.insertBefore(d,k);b[n]=h}})(window,document,"script","branch",function(b,r){b[r]=function(){b._q.push([r,arguments])}},{_q:[],_v:1},"addListener applyCode autoAppIndex banner closeBanner closeJourney creditHistory credits data deepview deepviewCta first getCode init link logout redeem referrals removeListener sendSMS setBranchViewData setIdentity track validateCode trackCommerceEvent logEvent".split(" "), 0);
branch.init('key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm', {metadata: {}, 'no_journeys': true, 'disable_exit_animation': true, 'disable_entry_animation': true, 'tracking_disabled': null}, function(err, data) {});</script><style id="googleidentityservice_button_styles">.qJTHM{-webkit-user-select:none;color:#202124;direction:ltr;-webkit-touch-callout:none;font-family:"Roboto-Regular",arial,sans-serif;-webkit-font-smoothing:antialiased;font-weight:400;margin:0;overflow:hidden;-webkit-text-size-adjust:100%}.ynRLnc{left:-9999px;position:absolute;top:-9999px}.L6cTce{display:none}.bltWBb{word-break:break-all}.hSRGPd{color:#1a73e8;cursor:pointer;font-weight:500;text-decoration:none}.Bz112c-W3lGp{height:16px;width:16px}.Bz112c-E3DyYd{height:20px;width:20px}.Bz112c-r9oPif{height:24px;width:24px}.Bz112c-uaxL4e{-webkit-border-radius:10px;border-radius:10px}.LgbsSe-Bz112c{display:block}.S9gUrf-YoZ4jf,.S9gUrf-YoZ4jf *{border:none;margin:0;padding:0}.fFW7wc-ibnC6b>.aZ2wEe>div{border-color:#4285f4}.P1ekSe-ZMv3u>div:nth-child(1){background-color:#1a73e8!important}.P1ekSe-ZMv3u>div:nth-child(2),.P1ekSe-ZMv3u>div:nth-child(3){background-image:linear-gradient(to right,rgba(255,255,255,.7),rgba(255,255,255,.7)),linear-gradient(to right,#1a73e8,#1a73e8)!important}.haAclf{display:inline-block}.nsm7Bb-HzV7m-LgbsSe{-webkit-border-radius:4px;border-radius:4px;-webkit-box-sizing:border-box;box-sizing:border-box;-webkit-transition:background-color .218s,border-color .218s;transition:background-color .218s,border-color .218s;-webkit-user-select:none;-webkit-appearance:none;background-color:#fff;background-image:none;border:1px solid #dadce0;color:#3c4043;cursor:pointer;font-family:"Google Sans",arial,sans-serif;font-size:14px;height:40px;letter-spacing:0.25px;outline:none;overflow:hidden;padding:0 12px;position:relative;text-align:center;vertical-align:middle;white-space:nowrap;width:auto}@media screen and (-ms-high-contrast:active){.nsm7Bb-HzV7m-LgbsSe{border:2px solid windowText;color:windowText}}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe{font-size:14px;height:32px;letter-spacing:0.25px;padding:0 10px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe{font-size:11px;height:20px;letter-spacing:0.3px;padding:0 8px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe{padding:0;width:40px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.pSzOP-SxQuSe{width:32px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.purZT-SxQuSe{width:20px}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK{-webkit-border-radius:20px;border-radius:20px}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK.pSzOP-SxQuSe{-webkit-border-radius:16px;border-radius:16px}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK.purZT-SxQuSe{-webkit-border-radius:10px;border-radius:10px}.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc{border:none;color:#fff}.nsm7Bb-HzV7m-LgbsSe.MFS4be-v3pZbf-Ia7Qfc{background-color:#1a73e8}.nsm7Bb-HzV7m-LgbsSe.MFS4be-JaPV2b-Ia7Qfc{background-color:#202124;color:#e8eaed}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{height:18px;margin-right:8px;min-width:18px;width:18px}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{height:14px;min-width:14px;width:14px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{height:10px;min-width:10px;width:10px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-Bz112c{margin-left:8px;margin-right:-4px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{margin:0;padding:10px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.pSzOP-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{padding:8px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c{padding:4px}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-top-left-radius:3px;border-top-left-radius:3px;-webkit-border-bottom-left-radius:3px;border-bottom-left-radius:3px;display:-webkit-box;display:-webkit-flex;display:flex;justify-content:center;-webkit-align-items:center;align-items:center;background-color:#fff;height:36px;margin-left:-10px;margin-right:12px;min-width:36px;width:36px}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf .nsm7Bb-HzV7m-LgbsSe-Bz112c,.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf .nsm7Bb-HzV7m-LgbsSe-Bz112c{margin:0;padding:0}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{height:28px;margin-left:-8px;margin-right:10px;min-width:28px;width:28px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{height:16px;margin-left:-6px;margin-right:8px;min-width:16px;width:16px}.nsm7Bb-HzV7m-LgbsSe.Bz112c-LgbsSe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:3px;border-radius:3px;margin-left:2px;margin-right:0;padding:0}.nsm7Bb-HzV7m-LgbsSe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:18px;border-radius:18px}.nsm7Bb-HzV7m-LgbsSe.pSzOP-SxQuSe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:14px;border-radius:14px}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:8px;border-radius:8px}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-bN97Pc-sM5MNb{display:-webkit-box;display:-webkit-flex;display:flex;-webkit-align-items:center;align-items:center;-webkit-flex-direction:row;flex-direction:row;justify-content:space-between;-webkit-flex-wrap:nowrap;flex-wrap:nowrap;height:100%;position:relative;width:100%}.nsm7Bb-HzV7m-LgbsSe .oXtfBe-l4eHX{justify-content:center}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-BPrWId{-webkit-flex-grow:1;flex-grow:1;font-family:"Google Sans",arial,sans-serif;font-weight:500;overflow:hidden;text-overflow:ellipsis;vertical-align:top}.nsm7Bb-HzV7m-LgbsSe.purZT-SxQuSe .nsm7Bb-HzV7m-LgbsSe-BPrWId{font-weight:300}.nsm7Bb-HzV7m-LgbsSe .oXtfBe-l4eHX .nsm7Bb-HzV7m-LgbsSe-BPrWId{-webkit-flex-grow:0;flex-grow:0}.nsm7Bb-HzV7m-LgbsSe .nsm7Bb-HzV7m-LgbsSe-MJoBVe{-webkit-transition:background-color .218s;transition:background-color .218s;bottom:0;left:0;position:absolute;right:0;top:0}.nsm7Bb-HzV7m-LgbsSe:hover,.nsm7Bb-HzV7m-LgbsSe:focus{-webkit-box-shadow:none;box-shadow:none;border-color:#d2e3fc;outline:none}.nsm7Bb-HzV7m-LgbsSe:hover .nsm7Bb-HzV7m-LgbsSe-MJoBVe,.nsm7Bb-HzV7m-LgbsSe:focus .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(66,133,244,.04)}.nsm7Bb-HzV7m-LgbsSe:active .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(66,133,244,.1)}.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc:hover .nsm7Bb-HzV7m-LgbsSe-MJoBVe,.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc:focus .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(255,255,255,.24)}.nsm7Bb-HzV7m-LgbsSe.MFS4be-Ia7Qfc:active .nsm7Bb-HzV7m-LgbsSe-MJoBVe{background:rgba(255,255,255,.32)}.nsm7Bb-HzV7m-LgbsSe .n1UuX-DkfjY{-webkit-border-radius:50%;border-radius:50%;display:-webkit-box;display:-webkit-flex;display:flex;height:20px;margin-left:-4px;margin-right:8px;min-width:20px;width:20px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId{font-family:"Roboto";font-size:12px;text-align:left}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .ssJRIf,.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff .fmcmS{overflow:hidden;text-overflow:ellipsis}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff{display:-webkit-box;display:-webkit-flex;display:flex;-webkit-align-items:center;align-items:center;color:#5f6368;fill:#5f6368;font-size:11px;font-weight:400}.nsm7Bb-HzV7m-LgbsSe.jVeSEe.MFS4be-Ia7Qfc .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff{color:#e8eaed;fill:#e8eaed}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-BPrWId .K4efff .Bz112c{height:18px;margin:-3px -3px -3px 2px;min-width:18px;width:18px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-top-left-radius:0;border-top-left-radius:0;-webkit-border-bottom-left-radius:0;border-bottom-left-radius:0;-webkit-border-top-right-radius:3px;border-top-right-radius:3px;-webkit-border-bottom-right-radius:3px;border-bottom-right-radius:3px;margin-left:12px;margin-right:-10px}.nsm7Bb-HzV7m-LgbsSe.jVeSEe.JGcpL-RbRzK .nsm7Bb-HzV7m-LgbsSe-Bz112c-haAclf{-webkit-border-radius:18px;border-radius:18px}.L5Fo6c-sM5MNb{border:0;display:block;left:0;position:relative;top:0}.L5Fo6c-bF1uUb{-webkit-border-radius:4px;border-radius:4px;bottom:0;cursor:pointer;left:0;position:absolute;right:0;top:0}.L5Fo6c-bF1uUb:focus{border:none;outline:none}sentinel{}</style><link id="googleidentityservice" type="text/css" media="all" rel="stylesheet" href="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/style"><meta http-equiv="origin-trial" content="AymqwRC7u88Y4JPvfIF2F37QKylC04248hLCdJAsh8xgOfe/dVJPV3XS3wLFca1ZMVOtnBfVjaCMTVudWM//5g4AAAB7eyJvcmlnaW4iOiJodHRwczovL3d3dy5nb29nbGV0YWdtYW5hZ2VyLmNvbTo0NDMiLCJmZWF0dXJlIjoiUHJpdmFjeVNhbmRib3hBZHNBUElzIiwiZXhwaXJ5IjoxNjk1MTY3OTk5LCJpc1RoaXJkUGFydHkiOnRydWV9"></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div><script>if (window.self !== window.top) window.location = "about:blank"</script></div><div class="l c"><div class="l m n o c" style="transform: translateY(-57px);"><div class="p q r s t u v w x i d y z"><a class="dt ag du be ak b am an ao ap aq ar as at s u w i d q dv z" href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2Fc62f55af492d&amp;%7Efeature=LoOpenInAppButton&amp;%7Echannel=ShowPostUnderUser&amp;source=---two_column_layout_nav----------------------------------" rel="noopener follow">Open in app<svg width="10" height="10" viewBox="0 0 10 10" fill="none" class="ds"><path d="M.98 8.48a.37.37 0 1 0 .54.54l-.54-.54zm7.77-7.23h.38c0-.2-.17-.38-.38-.38v.38zM8.37 6.5a.37.37 0 1 0 .76 0h-.76zM3.5.87a.37.37 0 1 0 0 .76V.88zM1.52 9.03l7.5-7.5-.54-.54-7.5 7.5.54.54zm6.86-7.77V6.5h.74V1.25h-.74zm-4.88.38h5.25V.88H3.5v.74z" fill="currentColor"></path></svg></a><div class="ab q"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><button class="be b dw dx eg dy dz eh ea eb ei ej ed ek el ef em eo ep eq er es et eu ev ew ex ey ez fa fb fc bl fd fe" data-testid="headerSignUpButton">Sign up</button></span></p><div class="aw l"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSignInButton" rel="noopener follow" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Fmedium.com%2F%40baptisteloquette.entr%2Flangchain-arxiv-tutor-data-loading-c62f55af492d&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------">Sign in</a></span></p></div></div></div><div class="p q r ab ac"><div class="ab q ae"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab" aria-label="Homepage" data-testid="headerMediumLogo" rel="noopener follow" href="https://medium.com/?source=---two_column_layout_nav----------------------------------"><svg viewBox="0 0 3940 610" class="au av"><path d="M594.79 308.2c0 163.76-131.85 296.52-294.5 296.52S5.8 472 5.8 308.2 137.65 11.69 300.29 11.69s294.5 132.75 294.5 296.51M917.86 308.2c0 154.16-65.93 279.12-147.25 279.12s-147.25-125-147.25-279.12S689.29 29.08 770.61 29.08s147.25 125 147.25 279.12M1050 308.2c0 138.12-23.19 250.08-51.79 250.08s-51.79-112-51.79-250.08 23.19-250.08 51.8-250.08S1050 170.09 1050 308.2M1862.77 37.4l.82-.18v-6.35h-167.48l-155.51 365.5-155.51-365.5h-180.48v6.35l.81.18c30.57 6.9 46.09 17.19 46.09 54.3v434.45c0 37.11-15.58 47.4-46.15 54.3l-.81.18V587H1327v-6.35l-.81-.18c-30.57-6.9-46.09-17.19-46.09-54.3V116.9L1479.87 587h11.33l205.59-483.21V536.9c-2.62 29.31-18 38.36-45.68 44.61l-.82.19v6.3h213.3v-6.3l-.82-.19c-27.71-6.25-43.46-15.3-46.08-44.61l-.14-445.2h.14c0-37.11 15.52-47.4 46.08-54.3m97.43 287.8c3.49-78.06 31.52-134.4 78.56-135.37 14.51.24 26.68 5 36.14 14.16 20.1 19.51 29.55 60.28 28.09 121.21zm-2.11 22h250v-1.05c-.71-59.69-18-106.12-51.34-138-28.82-27.55-71.49-42.71-116.31-42.71h-1c-23.26 0-51.79 5.64-72.09 15.86-23.11 10.7-43.49 26.7-60.45 47.7-27.3 33.83-43.84 79.55-47.86 130.93-.13 1.54-.24 3.08-.35 4.62s-.18 2.92-.25 4.39a332.64 332.64 0 0 0-.36 21.69C1860.79 507 1923.65 600 2035.3 600c98 0 155.07-71.64 169.3-167.8l-7.19-2.53c-25 51.68-69.9 83-121 79.18-69.76-5.22-123.2-75.95-118.35-161.63m532.69 157.68c-8.2 19.45-25.31 30.15-48.24 30.15s-43.89-15.74-58.78-44.34c-16-30.7-24.42-74.1-24.42-125.51 0-107 33.28-176.21 84.79-176.21 21.57 0 38.55 10.7 46.65 29.37zm165.84 76.28c-30.57-7.23-46.09-18-46.09-57V5.28L2424.77 60v6.7l1.14-.09c25.62-2.07 43 1.47 53.09 10.79 7.9 7.3 11.75 18.5 11.75 34.26v71.14c-18.31-11.69-40.09-17.38-66.52-17.38-53.6 0-102.59 22.57-137.92 63.56-36.83 42.72-56.3 101.1-56.3 168.81C2230 518.72 2289.53 600 2378.13 600c51.83 0 93.53-28.4 112.62-76.3V588h166.65v-6.66zm159.29-505.33c0-37.76-28.47-66.24-66.24-66.24-37.59 0-67 29.1-67 66.24s29.44 66.24 67 66.24c37.77 0 66.24-28.48 66.24-66.24m43.84 505.33c-30.57-7.23-46.09-18-46.09-57h-.13V166.65l-166.66 47.85v6.5l1 .09c36.06 3.21 45.93 15.63 45.93 57.77V588h166.8v-6.66zm427.05 0c-30.57-7.23-46.09-18-46.09-57V166.65L3082 212.92v6.52l.94.1c29.48 3.1 38 16.23 38 58.56v226c-9.83 19.45-28.27 31-50.61 31.78-36.23 0-56.18-24.47-56.18-68.9V166.66l-166.66 47.85V221l1 .09c36.06 3.2 45.94 15.62 45.94 57.77v191.27a214.48 214.48 0 0 0 3.47 39.82l3 13.05c14.11 50.56 51.08 77 109 77 49.06 0 92.06-30.37 111-77.89v66h166.66v-6.66zM3934.2 588v-6.67l-.81-.19c-33.17-7.65-46.09-22.07-46.09-51.43v-243.2c0-75.83-42.59-121.09-113.93-121.09-52 0-95.85 30.05-112.73 76.86-13.41-49.6-52-76.86-109.06-76.86-50.12 0-89.4 26.45-106.25 71.13v-69.87l-166.66 45.89v6.54l1 .09c35.63 3.16 45.93 15.94 45.93 57V588h155.5v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66V255.72c7-16.35 21.11-35.72 49-35.72 34.64 0 52.2 24 52.2 71.28V588h155.54v-6.66l-.82-.2c-26.46-6.22-35-17.56-35-46.66v-248a160.45 160.45 0 0 0-2.2-27.68c7.42-17.77 22.34-38.8 51.37-38.8 35.13 0 52.2 23.31 52.2 71.28V588z"></path></svg></a><div class="aw h"><div class="ab ax ay az ba q bb bc"><div class="bl" aria-hidden="false" aria-describedby="searchResults" aria-labelledby="searchResults"></div><div class="bm bn ab"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.1 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0zm6.94-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .8-.79l-3.74-3.73A8.05 8.05 0 0 0 11.04 3v.01z" fill="currentColor"></path></svg></div><input role="combobox" aria-controls="searchResults" aria-expanded="false" aria-label="search" data-testid="headerSearchInput" tabindex="0" class="ax bd be bf z bg bh bi bj bk" placeholder="Search" value=""></div></div></div><div class="h k w ff fg"><div class="fh ab"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerWriteButton" rel="noopener follow" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fnew-story&amp;source=---two_column_layout_nav-----------------------new_post_topnav-----------"><div class="be b bf z dt fi fj ab q fk fl"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Write"><path d="M14 4a.5.5 0 0 0 0-1v1zm7 6a.5.5 0 0 0-1 0h1zm-7-7H4v1h10V3zM3 4v16h1V4H3zm1 17h16v-1H4v1zm17-1V10h-1v10h1zm-1 1a1 1 0 0 0 1-1h-1v1zM3 20a1 1 0 0 0 1 1v-1H3zM4 3a1 1 0 0 0-1 1h1V3z" fill="currentColor"></path><path d="M17.5 4.5l-8.46 8.46a.25.25 0 0 0-.06.1l-.82 2.47c-.07.2.12.38.31.31l2.47-.82a.25.25 0 0 0 .1-.06L19.5 6.5m-2-2l2.32-2.32c.1-.1.26-.1.36 0l1.64 1.64c.1.1.1.26 0 .36L19.5 6.5m-2-2l2 2" stroke="currentColor"></path></svg><div class="ds l">Write</div></div></a></span></div></div><div class="k j i d"><div class="fh ab"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSearchButton" rel="noopener follow" href="https://medium.com/search?source=---two_column_layout_nav----------------------------------"><div class="be b bf z dt fi fj ab q fk fl"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" aria-label="Search"><path fill-rule="evenodd" clip-rule="evenodd" d="M4.1 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0zm6.94-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .8-.79l-3.74-3.73A8.05 8.05 0 0 0 11.04 3v.01z" fill="currentColor"></path></svg></div></a></div></div><div class="fh h k j"><div class="ab q"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><button class="be b dw dx eg dy dz eh ea eb ei ej ed ek el ef em eo ep eq er es et eu ev ew ex ey ez fa fb fc bl fd fe" data-testid="headerSignUpButton">Sign up</button></span></p><div class="aw l"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSignInButton" rel="noopener follow" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Fmedium.com%2F%40baptisteloquette.entr%2Flangchain-arxiv-tutor-data-loading-c62f55af492d&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------">Sign in</a></span></p></div></div></div><div class="l" aria-hidden="false"><button class="ax fm am ab q ao fn fo fp" aria-label="user options menu" data-testid="headerUserIcon"><div class="l fi"><img alt="" class="l fc bx by bz cw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_dmbNkD5D-u45r44go_cf0g.png" width="32" height="32" loading="lazy" role="presentation"><div class="fq bx l by bz fr n ax fs"></div></div></button></div></div></div><div class="l"><div class="sc" role="dialog" aria-modal="true" tabindex="-1"><div class="ww wx bg dv uc wy ty ao wz gl xa" aria-hidden="true" role="presentation"></div><div class="xb uc xc xd xe ww dv fc xf xg xh lq xi xj ud xk xl xm xn xo xp" aria-hidden="true"></div></div><div class="ft fu fv fw fx l"><div class="ab ca"><div class="ch bg fy fz ga gb"></div></div><article><div class="l"><div class="l"><span class="l"></span><section><div><div class="fr gh gi gj gk gl"></div><div class="gm gn go gp gq"><div class="ab ca"><div class="ch bg fy fz ga gb"><figure class="gu gv gw gx gy gz gr gs paragraph-image"><div class="gr gs gt"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*UpAKNhJYTpaQ4eWJKzWeDQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*UpAKNhJYTpaQ4eWJKzWeDQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*UpAKNhJYTpaQ4eWJKzWeDQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*UpAKNhJYTpaQ4eWJKzWeDQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*UpAKNhJYTpaQ4eWJKzWeDQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*UpAKNhJYTpaQ4eWJKzWeDQ.png 1100w, https://miro.medium.com/v2/resize:fit:1024/format:webp/1*UpAKNhJYTpaQ4eWJKzWeDQ.png 1024w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 512px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*UpAKNhJYTpaQ4eWJKzWeDQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*UpAKNhJYTpaQ4eWJKzWeDQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*UpAKNhJYTpaQ4eWJKzWeDQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*UpAKNhJYTpaQ4eWJKzWeDQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*UpAKNhJYTpaQ4eWJKzWeDQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*UpAKNhJYTpaQ4eWJKzWeDQ.png 1100w, https://miro.medium.com/v2/resize:fit:1024/1*UpAKNhJYTpaQ4eWJKzWeDQ.png 1024w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 512px"><img alt="" class="bg ha hb c" width="512" height="512" loading="eager" role="presentation" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_UpAKNhJYTpaQ4eWJKzWeDQ.png"></picture></div></figure><div><h1 id="d5a3" class="pw-post-title hc hd he be hf hg hh hi hj hk hl hm hn ho hp hq hr hs ht hu hv hw hx hy hz ia ib ic id ie bj" data-testid="storyTitle" data-selectable-paragraph="">Data Loading, OCR and Chunking – LangChain Arxiv Tutor</h1><div class="if ig ih ii ij"><div class="speechify-ignore ab co"><div class="speechify-ignore bg l"><div class="ik il im in io ab"><div><div class="ab ip"><a rel="noopener follow" href="https://medium.com/@baptisteloquette.entr?source=post_page-----c62f55af492d--------------------------------"><div><div class="bl" aria-hidden="false" aria-describedby="1" aria-labelledby="1"><div class="l iq ir bx is it"><div class="l fi"><img alt="Baptiste L." class="l fc bx dc dd cw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_jiwQ9IOKR15F1zwNKrN_Ow.png" width="44" height="44" loading="lazy" data-testid="authorPhoto"><div class="iu bx l dc dd fr n iv fs"></div></div></div></div></div></a></div></div><div class="bm bg l"><div class="ab"><div style="flex:1"><span class="be b bf z bj"><div class="iw ab q"><div class="ab q ix"><div class="ab q"><div><div class="bl" aria-hidden="false" aria-describedby="2" aria-labelledby="2"><p class="be b iy iz bj"><a class="af ag ah ai aj ak al am an ao ap aq ar ja" data-testid="authorName" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr?source=post_page-----c62f55af492d--------------------------------">Baptiste L.</a></p></div></div></div><span class="jb jc" aria-hidden="true"><span class="be b bf z dt">·</span></span><p class="be b iy iz dt"><span><a class="jd je ah ai aj ak al am an ao ap aq ar ew jf jg" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F7e94df6b7255&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40baptisteloquette.entr%2Flangchain-arxiv-tutor-data-loading-c62f55af492d&amp;user=Baptiste+L.&amp;userId=7e94df6b7255&amp;source=post_page-7e94df6b7255----c62f55af492d---------------------post_header-----------">Follow</a></span></p></div></div></span></div></div><div class="l jh"><span class="be b bf z dt"><div class="ab cm ji jj jk"><span class="be b bf z dt"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="jl jm l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="be b bf z dt">·</span></span></div><span data-testid="storyPublishDate">Jul 6, 2023</span></div></span></div></span></div></div></div><div class="ab co jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc"><div class="h k w ff fg q"><div class="ks l"><div class="ab q kt"><div class="pw-multi-vote-icon fi ku kv kw kx"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerClapButton" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc62f55af492d&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40baptisteloquette.entr%2Flangchain-arxiv-tutor-data-loading-c62f55af492d&amp;user=Baptiste+L.&amp;userId=7e94df6b7255&amp;source=-----c62f55af492d---------------------clap_footer-----------"><div><div class="bl" aria-hidden="false" aria-describedby="3" aria-labelledby="3"><div class="ky ao kz la lb lc am ld le lf kx"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lg lh li lj lk ll lm"><div><div class="bl" aria-hidden="false" aria-describedby="46" aria-labelledby="46"><p class="be b du z dt"><button class="af ag ah ai aj ak al am an ao ap aq ar as at xr lv">89<span class="l h g f sh si"></span></button></p></div></div></div></div></div><div><div class="bl" aria-hidden="false" aria-describedby="4" aria-labelledby="4"><button class="ao ky lq lr ab q fj ls lt" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" class="lp"><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count lo lp">3</span></p></button></div></div></div><div class="ab q kd ke kf kg kh ki kj kk kl km kn ko kp kq kr"><div class="lu k j i d"></div><div class="h k"><div><div class="bl" aria-hidden="false" aria-describedby="5" aria-labelledby="5"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerBookmarkButton" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc62f55af492d&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40baptisteloquette.entr%2Flangchain-arxiv-tutor-data-loading-c62f55af492d&amp;source=-----c62f55af492d---------------------bookmark_footer-----------"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="dt lv" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="currentColor"></path></svg></a></span></div></div></div><div class="fc lw cm"><div class="l ae"><div class="ab ca"><div class="lx ly lz ma mb ha ch bg"><div class="ab"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3Dc62f55af492d&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40baptisteloquette.entr%2Flangchain-arxiv-tutor-data-loading-c62f55af492d&amp;source=-----c62f55af492d---------------------post_audio_button-----------"><div><div class="bl" aria-hidden="false" aria-describedby="49" aria-labelledby="49"><button aria-label="Listen" data-testid="audioPlayButton" class="af fj ah ai aj ak al mc an ao ap ew md me lt mf mg mh mi mj s mk ml mm mn mo mp mq u mr ms mt"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0zm9-10a10 10 0 1 0 0 20 10 10 0 0 0 0-20zm3.38 10.42l-4.6 3.06a.5.5 0 0 1-.78-.41V8.93c0-.4.45-.63.78-.41l4.6 3.06c.3.2.3.64 0 .84z" fill="currentColor"></path></svg><div class="j i d"><p class="be b bf z dt">Listen</p></div></button></div></div></a></span></div></div></div></div></div><div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bl" aria-hidden="false" aria-describedby="7" aria-labelledby="7"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af fj ah ai aj ak al mc an ao ap ew md me lt mf mg mh mi mj s mk ml mm mn mo mp mq u mr ms mt"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="currentColor"></path></svg><div class="j i d"><p class="be b bf z dt">Share</p></div></button></div></div></div></div></div></div></div></div></div><p id="7eda" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">This Series of Articles covers the usage of LangChain, to create an Arxiv Tutor. That will allow anyone to interact in different ways with the papers to enhance engagement, generate tests, …</p><p id="31b7" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">Here we will discuss Data Loading, OCR and Vector Databases storage</p><p id="8c8e" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">In this series of articles we will explore through the Arxiv Tutor the following paper :</p><p id="7263" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph=""><strong class="mw hf"><em class="ns">Unifying Large Language Models and Knowledge Graphs: A Roadmap</em></strong></p><p id="0186" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph=""><em class="ns">Shirui Pan, Senior Member, IEEE, Linhao Luo,<br>Yufei Wang, Chen Chen, Jiapu Wang, Xindong W</em></p><p id="d972" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">I selected a relatively long paper (28 pages), because for long documents you might want to considers some problems with the usage of LLMs</p><h1 id="e645" class="nt nu he be nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bj" data-selectable-paragraph="">Download Papers</h1><p id="b07e" class="pw-post-body-paragraph mu mv he mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr gm bj" data-selectable-paragraph="">First download the paper</p><pre class="ow ox oy oz pa pb pc pd bo pe ba bj"><span id="289d" class="pf nu he pc b bf pg ph l pi pj" data-selectable-paragraph=""><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-keyword">def</span> <span class="hljs-title.function">download_pdf_paper_from_url</span>(<span class="hljs-params">url</span>):<br>    paper_number    =   os.path.basename(url).strip(<span class="hljs-string">".pdf"</span>)<br>    res             =   requests.get(url)<br>    pdf_path        =   <span class="hljs-string">f"papers/<span class="hljs-subst">{paper_number}</span>.pdf"</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(pdf_path, <span class="hljs-string">'wb'</span>) <span class="hljs-keyword">as</span> f:<br>        f.write(res.content)<br>    <span class="hljs-keyword">return</span> paper_number<br><br>link            =   <span class="hljs-string">"https://arxiv.org/pdf/2306.08302.pdf"</span><br>paper_number    =   download_pdf_paper_from_url(link)</span></pre><p id="8d22" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">We load the paper using LangChain’s <code class="cw pk pl pm pc b">PDFMinerLoader</code> (There are different PDF Loaders, but PDFMiner (based on pdfminer.six) is my go-to especially for scientific litterature)</p><pre class="ow ox oy oz pa pb pc pd bo pe ba bj"><span id="72a0" class="pf nu he pc b bf pg ph l pi pj" data-selectable-paragraph=""><span class="hljs-keyword">from</span> langchain.document_loaders <span class="hljs-keyword">import</span> PDFMinerLoader<br>docs    =   PDFMinerLoader(<span class="hljs-string">f"papers/<span class="hljs-subst">{paper_number}</span>.pdf"</span>).load()</span></pre><h1 id="ea7d" class="nt nu he be nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bj" data-selectable-paragraph="">Chunking with LangChain</h1><p id="e032" class="pw-post-body-paragraph mu mv he mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr gm bj" data-selectable-paragraph="">Let’s chunk the content of the paper.</p><p id="6b66" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">We chunk the paper in order to have context lengths that do not hit the LLM’s tokens limitation, while trying to preserve semantics across the chunks.</p><p id="7616" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">LangChain offer <code class="cw pk pl pm pc b">RecursiveCharacterTextSplitter</code> that tries to preserve semantics by keeping the paragraphs together. Simply because paragraphs are generally grouped for a semantic reason.</p><p id="5e11" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">It does so by first trying to split with “\n\n” then “\n”, “ “, and finally “”.</p><pre class="ow ox oy oz pa pb pc pd bo pe ba bj"><span id="d92a" class="pf nu he pc b bf pg ph l pi pj" data-selectable-paragraph=""><span class="hljs-keyword">from</span> langchain.text_splitter <span class="hljs-keyword">import</span> RecursiveCharacterTextSplitter<br><br>text_splitter   =   RecursiveCharacterTextSplitter(<br>    chunk_size=<span class="hljs-number">700</span>, <span class="hljs-comment"># Specify the character chunk size</span><br>    chunk_overlap=<span class="hljs-number">0</span>, <span class="hljs-comment"># "Allowed" Overlap across chunks</span><br>    length_function=<span class="hljs-built_in">len</span> <span class="hljs-comment"># Function used to evaluate the chunk size (here in terms of characters)</span><br>)<br><br>docs    =   text_splitter.split_documents(docs)</span></pre><p id="80c3" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">This is what we get :</p><pre class="ow ox oy oz pa pb pc pd bo pe ba bj"><span id="1d08" class="pf nu he pc b bf pg ph l pi pj" data-selectable-paragraph="">[Document(page_content=<span class="hljs-comment">'3\n2\n0\n2\n\nn\nu\nJ\n\n0\n2\n\n]\nL\nC\n.\ns\nc\n[\n\n2\nv\n2\n0\n3\n8\n0\n.\n6\n0\n3\n2\n:\nv\ni\nX\nr\na\n\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\n\n1\n\nUnifying Large Language Models and\nKnowledge Graphs: A Roadmap\n\nShirui Pan, Senior Member, IEEE, Linhao Luo,\nYufei Wang, Chen Chen, Jiapu Wang, Xindong Wu, Fellow, IEEE', metadata={'source': 'papers/2306.08302.pdf'}),</span><br> Document(page_content=<span class="hljs-comment">'Abstract—Large language models (LLMs), such as ChatGPT and GPT4, are making new waves in the field of natural language\nprocessing and artificial intelligence, due to their emergent ability and generalizability. However, LLMs are black-box models, which\noften fall short of capturing and accessing factual knowledge. In contrast, Knowledge Graphs (KGs), Wikipedia and Huapu for example,\nare structured knowledge models that explicitly store rich factual knowledge. KGs can enhance LLMs by providing external knowledge\nfor inference and interpretability. Meanwhile, KGs are difficult to construct and evolving by nature, which challenges the existing', metadata={'source': 'papers/2306.08302.pdf'}),</span><br> Document(page_content=<span class="hljs-comment">'methods in KGs to generate new facts and represent unseen knowledge. Therefore, it is complementary to unify LLMs and KGs\ntogether and simultaneously leverage their advantages. In this article, we present a forward-looking roadmap for the unification of LLMs\nand KGs. Our roadmap consists of three general frameworks, namely, 1) KG-enhanced LLMs, which incorporate KGs during the\npre-training and inference phases of LLMs, or for the purpose of enhancing understanding of the knowledge learned by LLMs; 2)\nLLM-augmented KGs, that leverage LLMs for different KG tasks such as embedding, completion, construction, graph-to-text', metadata={'source': 'papers/2306.08302.pdf'}),</span><br>...,<br> Document(page_content=<span class="hljs-comment">'[256] T. Sun, Y. Shao, H. Qian, X. Huang, and X. Qiu, “Black-box tuning\nfor language-model-as-a-service,” in International Conference on\nMachine Learning. PMLR, 2022, pp. 20 841–20 855.\n\n[257] X. Chen, A. Shrivastava, and A. Gupta, “NEIL: extracting visual\nknowledge from web data,” in IEEE International Conference on\nComputer Vision, ICCV 2013, Sydney, Australia, December 1-8, 2013.\nIEEE Computer Society, 2013, pp. 1409–1416. [Online]. Available:\nhttps://doi.org/10.1109/ICCV.2013.178', metadata={'source': 'papers/2306.08302.pdf'}),</span><br> Document(page_content=<span class="hljs-comment">'[Online]. Available: https://ceur-ws.org/Vol-2276/paper5.pdf', metadata={'source': 'papers/2306.08302.pdf'}),</span><br> Document(page_content=<span class="hljs-comment">'[259] Z. Chen, Y. Huang, J. Chen, Y. Geng, Y. Fang, J. Z. Pan, N. Zhang,\nand W. Zhang, “Lako: Knowledge-driven visual estion answer-\ning via late knowledge-to-text injection,” 2022.\n\n[260] R. Girdhar, A. El-Nouby, Z. Liu, M. Singh, K. V. Alwala, A. Joulin,\nand I. Misra, “Imagebind: One embedding space to bind them\nall,” in Proceedings of the IEEE/CVF Conference on Computer Vision\nand Pattern Recognition, 2023, pp. 15 180–15 190.\n\n[261] J. Zhang, Z. Yin, P. Chen, and S. Nichele, “Emotion recognition\nusing multi-modal data and machine learning techniques: A\ntutorial and review,” Information Fusion, vol. 59, pp. 103–126,\n2020.', metadata={'source': 'papers/2306.08302.pdf'}),</span><br> Document(page_content=<span class="hljs-comment">'[262] Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and S. Y. Philip,\n“A comprehensive survey on graph neural networks,” IEEE\ntransactions on neural networks and learning systems, vol. 32, no. 1,\npp. 4–24, 2020.\n\n[263] T. Wu, M. Caccia, Z. Li, Y.-F. Li, G. Qi, and G. Haffari, “Pretrained\nlanguage model in continual learning: A comparative study,” in\nInternational Conference on Learning Representations, 2022.', metadata={'source': 'papers/2306.08302.pdf'})]]</span></span></pre><p id="c272" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">We can see that the results are good. But I want to handle the titles and exclude the references (as for interactions or any of our use cases, this is not valuable pieces of information)</p><p id="9bc2" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">To handle both, I propose OCR based parsing method.</p><h1 id="bf6c" class="nt nu he be nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bj" data-selectable-paragraph="">Layout Parsing with LayoutParser</h1><p id="071a" class="pw-post-body-paragraph mu mv he mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr gm bj" data-selectable-paragraph=""><code class="cw pk pl pm pc b">layoutparser</code> is a great library that offers different Computer Vision Models to perform layout analysis on Documents.</p><p id="5417" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">Note that these model will detect paragraphs, ultimately respecting the assumption that paragraphs are the most semantic piece of information.</p><div class="pn po pp pq pr ps"><a href="https://github.com/Layout-Parser/layout-parser?source=post_page-----c62f55af492d--------------------------------" rel="noopener  ugc nofollow" target="_blank"><div class="pt ab jh"><div class="pu ab cn ca pv pw"><h2 class="be hf iy z px py pz qa qb qc qd hd bj">GitHub - Layout-Parser/layout-parser: A Unified Toolkit for Deep Learning Based Document Image…</h2><div class="qe l"><h3 class="be b iy z px py pz qa qb qc qd dt">A Unified Toolkit for Deep Learning Based Document Image Analysis - GitHub - Layout-Parser/layout-parser: A Unified…</h3></div><div class="qf l"><p class="be b du z px py pz qa qb qc qd dt">github.com</p></div></div><div class="qg l"><div class="qh l qi qj qk qg ql ha ps"></div></div></div></a></div><p id="3864" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">We will use PubLayNet’s <code class="cw pk pl pm pc b">mask_rcnn_X_101_32x8d_FPN_3x</code> , that model is purposed to perform layout parsing of scientific papers.</p><p id="79bc" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">A Mask-RCNN comport 3 main components :</p><p id="dc70" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph=""><strong class="mw hf">First</strong> a convolutional NN to extract feature maps. <strong class="mw hf">Second</strong> a RPN (<em class="ns">Region Proposal Network</em>) that will make use of the feature maps to propose and refine a certain number of regions of interests. The <strong class="mw hf">Third</strong> component will gather the best propositions, then refine them further, to produce a segmentation mask.</p><ol class=""><li id="4ba9" class="mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr qm qn qo bj" data-selectable-paragraph=""><strong class="mw hf">First we convert the PDF’s into images using </strong><code class="cw pk pl pm pc b"><strong class="mw hf">pdf2image</strong></code></li></ol><pre class="ow ox oy oz pa pb pc pd bo pe ba bj"><span id="54e1" class="pf nu he pc b bf pg ph l pi pj" data-selectable-paragraph=""><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> pdf2image <span class="hljs-keyword">import</span> convert_from_path<br><br><span class="hljs-keyword">def</span> <span class="hljs-title.function">convert_pdf_to_images</span>(<span class="hljs-params">pdf_path</span>):<br>    img_path    =   os.path.join(<span class="hljs-string">"papers_images"</span>, os.path.basename(pdf_path).strip(<span class="hljs-string">".pdf"</span>) + <span class="hljs-string">"_images"</span>)<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(img_path):<br>        os.makedirs(img_path)<br>    images      =   convert_from_path(pdf_path=pdf_path)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(images)):<br>        images[i].save(os.path.join(img_path, <span class="hljs-string">"page"</span> + <span class="hljs-built_in">str</span>(i) + <span class="hljs-string">".jpg"</span>), <span class="hljs-string">"JPEG"</span>)<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">"Images Saved !"</span>)<br>    <span class="hljs-keyword">return</span> img_path<br><br>imgs_path   =   convert_pdf_to_images(<span class="hljs-string">f"papers/<span class="hljs-subst">{paper_number}</span>.pdf"</span>)</span></pre><p id="c725" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">2. <strong class="mw hf">Load the model</strong></p><pre class="ow ox oy oz pa pb pc pd bo pe ba bj"><span id="c5ec" class="pf nu he pc b bf pg ph l pi pj" data-selectable-paragraph=""><span class="hljs-keyword">import</span> layoutparser <span class="hljs-keyword">as</span> lp<br><br>model_publay    =   lp.Detectron2LayoutModel(<span class="hljs-string">'lp://PubLayNet/mask_rcnn_X_101_32x8d_FPN_3x/config'</span>,<br>                    extra_config=[<span class="hljs-string">"MODEL.ROI_HEADS.SCORE_THRESH_TEST"</span>, <span class="hljs-number">0.6</span>],<br>                    label_map={<span class="hljs-number">0</span>: <span class="hljs-string">"Text"</span>, <span class="hljs-number">1</span>: <span class="hljs-string">"Title"</span>, <span class="hljs-number">2</span>: <span class="hljs-string">"List"</span>, <span class="hljs-number">3</span>:<span class="hljs-string">"Table"</span>, <span class="hljs-number">4</span>:<span class="hljs-string">"Figure"</span>})</span></pre><p id="3553" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">As you can see we need to specify a “<em class="ns">confidence</em>”<em class="ns"> </em>threshold. Then we just specify the mapping of the labels for convenience.</p><p id="3603" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">Let’s see the model in action</p><pre class="ow ox oy oz pa pb pc pd bo pe ba bj"><span id="f59f" class="pf nu he pc b bf pg ph l pi pj" data-selectable-paragraph=""><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> os<br><br>page_idx    =   <span class="hljs-number">6</span><br>img_path    =   os.path.join(pdf_path, <span class="hljs-string">f"page<span class="hljs-subst">{page_idx}</span>.jpg"</span>)<br>img         =   cv2.imread(img_path)<br>img         =   img[..., ::-<span class="hljs-number">1</span>]</span></pre><pre class="qp pb pc pd bo pe ba bj"><span id="aba3" class="pf nu he pc b bf pg ph l pi pj" data-selectable-paragraph="">layout  =   model_publay.detect(img)<br>lp.draw_box(img, layout)</span></pre><figure class="ow ox oy oz pa gz gr gs paragraph-image"><div role="button" tabindex="0" class="qr qs fi qt bg qu"><div class="gr gs qq"><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/1*L_qB_D0tu3xQqftuIZcPGw.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*L_qB_D0tu3xQqftuIZcPGw.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*L_qB_D0tu3xQqftuIZcPGw.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*L_qB_D0tu3xQqftuIZcPGw.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*L_qB_D0tu3xQqftuIZcPGw.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*L_qB_D0tu3xQqftuIZcPGw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/1*L_qB_D0tu3xQqftuIZcPGw.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/1*L_qB_D0tu3xQqftuIZcPGw.png 640w, https://miro.medium.com/v2/resize:fit:720/1*L_qB_D0tu3xQqftuIZcPGw.png 720w, https://miro.medium.com/v2/resize:fit:750/1*L_qB_D0tu3xQqftuIZcPGw.png 750w, https://miro.medium.com/v2/resize:fit:786/1*L_qB_D0tu3xQqftuIZcPGw.png 786w, https://miro.medium.com/v2/resize:fit:828/1*L_qB_D0tu3xQqftuIZcPGw.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*L_qB_D0tu3xQqftuIZcPGw.png 1100w, https://miro.medium.com/v2/resize:fit:1400/1*L_qB_D0tu3xQqftuIZcPGw.png 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"><img alt="" class="bg ha hb c" width="700" height="906" loading="lazy" role="presentation" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_L_qB_D0tu3xQqftuIZcPGw.png"></picture></div></div></figure><p id="d423" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">As we can see it detects Figures, Titles and Texts, it also can detect Lists. While this can be seen as non-necessary, it will really be useful in the next articles.</p><p id="5931" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">As this article is not about OCR, I will only explain briefly the following piece of code :</p><pre class="ow ox oy oz pa pb pc pd bo pe ba bj"><span id="7651" class="pf nu he pc b bf pg ph l pi pj" data-selectable-paragraph=""><span class="hljs-keyword">def</span> <span class="hljs-title.function">get_coordinate</span>(<span class="hljs-params">data</span>):<br><br>  x1 = data.block.x_1<br>  y1 = data.block.y_1<br>  x2 = data.block.x_2<br>  y2 = data.block.y_2<br><br>  <span class="hljs-keyword">return</span> torch.tensor([[x1, y1, x2, y2]], dtype=torch.<span class="hljs-built_in">float</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title.function">get_iou</span>(<span class="hljs-params">box_1, box_2</span>):<br><br>  <span class="hljs-keyword">return</span> bops.box_iou(box_1, box_2)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title.function">get_area</span>(<span class="hljs-params">bbox</span>):<br>  w = bbox[<span class="hljs-number">0</span>, <span class="hljs-number">2</span>] - bbox[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>] <span class="hljs-comment"># Width</span><br>  h = bbox[<span class="hljs-number">0</span>, <span class="hljs-number">3</span>] - bbox[<span class="hljs-number">0</span>, <span class="hljs-number">1</span>] <span class="hljs-comment"># Height</span><br>  area  = w * h<br><br>  <span class="hljs-keyword">return</span> area<br><br><span class="hljs-keyword">def</span> <span class="hljs-title.function">refine_bboxes</span>(<span class="hljs-params">block_1, block_2</span>):<br><br>  bb1 = set_coordinate(block_1)<br>  bb2 = set_coordinate(block_2)<br><br>  iou = get_iou(bb1, bb2)<br><br>  <span class="hljs-keyword">if</span> iou.tolist()[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] != <span class="hljs-number">0.0</span>:<br><br>    a1 = get_area(bb1)<br>    a2 = get_area(bb2)<br><br>    block_2.<span class="hljs-built_in">set</span>(<span class="hljs-built_in">type</span>=<span class="hljs-string">'None'</span>, inplace= <span class="hljs-literal">True</span>) <span class="hljs-keyword">if</span> a1 &gt; a2 <span class="hljs-keyword">else</span> block_1.<span class="hljs-built_in">set</span>(<span class="hljs-built_in">type</span>=<span class="hljs-string">'None'</span>, inplace= <span class="hljs-literal">True</span>)</span></pre><p id="4522" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">Here handle bboxes overlaps by computing the IntersectionOverUnion of each detected bboxes. If IoU &gt; 0 then we have an overlap, we thus compute the area of the 2 overlapping bboxes, and only keep the bbox with the greatest area, by setting it’s <code class="cw pk pl pm pc b">type</code> to <code class="cw pk pl pm pc b">"None"</code> .</p><pre class="ow ox oy oz pa pb pc pd bo pe ba bj"><span id="6781" class="pf nu he pc b bf pg ph l pi pj" data-selectable-paragraph="">ocr_agent                   =   lp.TesseractAgent(languages=<span class="hljs-string">"eng"</span>)<br><br><span class="hljs-keyword">def</span> <span class="hljs-title.function">extract_text_pdf_image_PubLay_OCR</span>(<span class="hljs-params">img_path</span>):<br>    texts       =   []<br>    image       =   cv2.imread(img_path)<br>    image       =   image[..., ::-<span class="hljs-number">1</span>]<br>    layout      =   model_publay.detect(image)<br>    text_blocks =   lp.Layout([b <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> layout <span class="hljs-keyword">if</span> b.<span class="hljs-built_in">type</span> <span class="hljs-keyword">in</span> [<span class="hljs-string">'Text'</span>, <span class="hljs-string">'List'</span>, <span class="hljs-string">'Title'</span>]])<br><br>    <span class="hljs-comment"># Organize text blocks based on their positions on the page</span><br>    h, w            =   image.shape[:<span class="hljs-number">2</span>]<br>    left_interval   =   lp.Interval(<span class="hljs-number">0</span>, w/<span class="hljs-number">2</span>*<span class="hljs-number">1.05</span>, axis=<span class="hljs-string">'x'</span>).put_on_canvas(image)<br>    left_blocks     =   text_blocks.filter_by(left_interval, center=<span class="hljs-literal">True</span>)<br>    left_blocks.sort(key = <span class="hljs-keyword">lambda</span> b:b.coordinates[<span class="hljs-number">1</span>], inplace=<span class="hljs-literal">True</span>)<br><br>    right_blocks            =   lp.Layout([b <span class="hljs-keyword">for</span> b <span class="hljs-keyword">in</span> text_blocks <span class="hljs-keyword">if</span> b <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> left_blocks])<br>    right_blocks.sort(key   =   <span class="hljs-keyword">lambda</span> b:b.coordinates[<span class="hljs-number">1</span>], inplace=<span class="hljs-literal">True</span>)<br><br>    text_blocks = lp.Layout([b.<span class="hljs-built_in">set</span>(<span class="hljs-built_in">id</span> = idx) <span class="hljs-keyword">for</span> idx, b <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(left_blocks + right_blocks)])<br><br>    <span class="hljs-keyword">for</span> layout_i <span class="hljs-keyword">in</span> text_blocks:    <span class="hljs-comment"># If some of the blocks overlap -&gt; Take the one with the most associated area</span><br>        <span class="hljs-keyword">for</span> layout_j <span class="hljs-keyword">in</span> text_blocks:<br>            <span class="hljs-keyword">if</span> layout_i != layout_j:<br>                refine_blocks(layout_i, layout_j)<br><br>    <span class="hljs-keyword">for</span> block <span class="hljs-keyword">in</span> text_blocks:<br>        segment_image = (block<br>                        .pad(left=<span class="hljs-number">5</span>, right=<span class="hljs-number">5</span>, top=<span class="hljs-number">5</span>, bottom=<span class="hljs-number">5</span>)<br>                        .crop_image(image))<br>            <span class="hljs-comment"># add padding in each image segment can help</span><br>            <span class="hljs-comment"># improve robustness </span><br>            <br>        text = ocr_agent.detect(segment_image)<br>        block.<span class="hljs-built_in">set</span>(text=text, inplace=<span class="hljs-literal">True</span>)<br>    <span class="hljs-keyword">for</span> l <span class="hljs-keyword">in</span> text_blocks:<br>        texts.append([l.text, l.<span class="hljs-built_in">type</span>])<br>    <span class="hljs-keyword">return</span> texts</span></pre><p id="3b35" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">Here we :</p><ol class=""><li id="d9f8" class="mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr qm qn qo bj" data-selectable-paragraph="">Initialize the <code class="cw pk pl pm pc b">ocr_agent</code> that will extract the text from the detected boxes, using Tesseract. Note that you can specify multiple languages with the following format : <code class="cw pk pl pm pc b">languages=["eng", "fra"]</code> .</li><li id="7331" class="mu mv he mw b mx qv mz na nb qw nd ne nf qx nh ni nj qy nl nm nn qz np nq nr qm qn qo bj" data-selectable-paragraph="">Pass the image through the model. Only keeping the bboxes detected with labels “Text”, “Title”, or “List”. Ultimately excluding Figures.</li><li id="7ee5" class="mu mv he mw b mx qv mz na nb qw nd ne nf qx nh ni nj qy nl nm nn qz np nq nr qm qn qo bj" data-selectable-paragraph="">Sort the boxes by their positions on the page. Note that paper’s pages can be in 2 columns, we thus sort from top to bottom, then left to right</li><li id="f6db" class="mu mv he mw b mx qv mz na nb qw nd ne nf qx nh ni nj qy nl nm nn qz np nq nr qm qn qo bj" data-selectable-paragraph="">Apply the <code class="cw pk pl pm pc b">refine_blocks</code> function to handle bboxe’s overlap</li><li id="5771" class="mu mv he mw b mx qv mz na nb qw nd ne nf qx nh ni nj qy nl nm nn qz np nq nr qm qn qo bj" data-selectable-paragraph="">Infer the text for each bboxes, here we pad each images by 5. Padding improve the <code class="cw pk pl pm pc b">ocr_agent</code>‘s accuracy.</li><li id="8011" class="mu mv he mw b mx qv mz na nb qw nd ne nf qx nh ni nj qy nl nm nn qz np nq nr qm qn qo bj" data-selectable-paragraph="">Append to a list the texts and the labels.</li></ol><pre class="ow ox oy oz pa pb pc pd bo pe ba bj"><span id="db36" class="pf nu he pc b bf pg ph l pi pj" data-selectable-paragraph=""><span class="hljs-keyword">def</span> <span class="hljs-title.function">images_2_OCR</span>(<span class="hljs-params">imgs_paths</span>):<br>    docs        =   []<br>    <span class="hljs-keyword">for</span> img_path_idx <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(os.listdir(imgs_paths))):<br>        img_path        =   os.path.join(imgs_paths, <span class="hljs-string">"page{}.jpg"</span>.<span class="hljs-built_in">format</span>(img_path_idx))<br>        page_content    =   extract_text_pdf_image_PubLay_OCR(img_path)<br>        <span class="hljs-keyword">for</span> content <span class="hljs-keyword">in</span> page_content:<br>            text    =   content[<span class="hljs-number">0</span>]<br>            cat     =   content[<span class="hljs-number">1</span>]<br>            <span class="hljs-keyword">if</span> <span class="hljs-string">"REFERENCES"</span> <span class="hljs-keyword">in</span> text <span class="hljs-keyword">and</span> cat == <span class="hljs-string">"Title"</span>:<br>                <span class="hljs-keyword">return</span> docs<br>            metadata        =   {<span class="hljs-string">"page_number"</span> : img_path_idx, <span class="hljs-string">"category"</span> : cat, <span class="hljs-string">"source"</span> : paper_number}<br>            docs.append(Document(page_content=text, metadata=metadata))<br><br>    <span class="hljs-keyword">return</span> docs</span></pre><p id="efb3" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">In this function, for each image we detect the text. Then create a list of LangChain Documents with metadatas.</p><p id="99ab" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">Note that we exclude all the References with :</p><pre class="ow ox oy oz pa pb pc pd bo pe ba bj"><span id="7d2b" class="pf nu he pc b bf pg ph l pi pj" data-selectable-paragraph=""><span class="hljs-keyword">if</span> <span class="hljs-string">"REFERENCES"</span> <span class="hljs-keyword">in</span> text <span class="hljs-keyword">and</span> cat == <span class="hljs-string">"Title"</span>:<br>  <span class="hljs-keyword">return</span> docs</span></pre><h1 id="d7ef" class="nt nu he be nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bj" data-selectable-paragraph="">Add the referenced papers</h1><p id="cb65" class="pw-post-body-paragraph mu mv he mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr gm bj" data-selectable-paragraph="">While the text referencing the papers, is not valuable for tasks like RetrievalQA, and especially Summarization. We can make use of the referenced papers to get “Out-of-scope” contexts.</p><p id="3f99" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">First we gather the referenced Arxiv paper’s number through the mentionned URLs :</p><pre class="ow ox oy oz pa pb pc pd bo pe ba bj"><span id="4e3a" class="pf nu he pc b bf pg ph l pi pj" data-selectable-paragraph="">adjacents_papers_urls       =   []<br>adjacents_papers_numbers    =   []<br><span class="hljs-keyword">for</span> doc <span class="hljs-keyword">in</span> docs:<br>    adjacents_papers_urls.extend([re.sub(<span class="hljs-string">"abs"</span>, <span class="hljs-string">"pdf"</span>, url) + <span class="hljs-string">".pdf"</span> <span class="hljs-keyword">for</span> url <span class="hljs-keyword">in</span> re.findall(<span class="hljs-string">r'(https?://arxiv.org/abs\S+)'</span>, doc.page_content)])<br>    adjacents_papers_numbers.extend([re.findall(<span class="hljs-string">'\d{4}\.\d{5}'</span>, url)[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> url <span class="hljs-keyword">in</span> re.findall(<span class="hljs-string">r'(https?://arxiv.org/abs\S+)'</span>, doc.page_content)])</span></pre><p id="9a14" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">Then iterate over those retrieved numbers and chunk :</p><pre class="ow ox oy oz pa pb pc pd bo pe ba bj"><span id="66de" class="pf nu he pc b bf pg ph l pi pj" data-selectable-paragraph=""><span class="hljs-keyword">from</span> langchain.document_loaders <span class="hljs-keyword">import</span> ArxivLoader<br><span class="hljs-keyword">for</span> pdf_number <span class="hljs-keyword">in</span> adjacents_papers_numbers:<br>    adj_docs    =   ArxivLoader(query=pdf_number)<br>    adj_docs    =   PDFMinerLoader(<span class="hljs-string">f"papers/<span class="hljs-subst">{pdf_number}</span>.pdf"</span>).load()<br>    adj_docs    =   text_splitter.split_documents(docs)<br>    vdb_chunks.add_documents(docs)</span></pre><p id="3103" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">Of course you can do this recursively for every mentioned papers.</p></div></div></div><div class="ab ca ra rb rc rd" role="separator"><span class="re bx bl rf rg rh"></span><span class="re bx bl rf rg rh"></span><span class="re bx bl rf rg"></span></div><div class="gm gn go gp gq"><div class="ab ca"><div class="ch bg fy fz ga gb"><p id="b7d1" class="pw-post-body-paragraph mu mv he mw b mx my mz na nb nc nd ne nf ng nh ni nj nk nl nm nn no np nq nr gm bj" data-selectable-paragraph="">In the next article we will populate a Vector Database and begin coding the interaction part.</p><h1 id="993f" class="nt nu he be nv nw nx ny nz oa ob oc od oe of og oh oi oj ok ol om on oo op oq bj" data-selectable-paragraph="">Few Notes :</h1><ul class=""><li id="d8ba" class="mu mv he mw b mx or mz na nb os nd ne nf ot nh ni nj ou nl nm nn ov np nq nr ri qn qo bj" data-selectable-paragraph="">Performing OCR for layout parsing is a good idea, but you must consider that it takes more computing.</li><li id="fed8" class="mu mv he mw b mx qv mz na nb qw nd ne nf qx nh ni nj qy nl nm nn qz np nq nr ri qn qo bj" data-selectable-paragraph="">Deploying such models will be costlier than using LangChain’s Loader or any deterministic chunking methods.</li><li id="f472" class="mu mv he mw b mx qv mz na nb qw nd ne nf qx nh ni nj qy nl nm nn qz np nq nr ri qn qo bj" data-selectable-paragraph="">As the “layout-parsing” model is trained on mostly specific format (here scientific litterature), it can not generalize well on other documents, especially with one’s full of colors. The <code class="cw pk pl pm pc b">layoutparser</code> library offers other models for different types of Documents, that you can explore.</li></ul></div></div></div></div></section></div></div></article><div class="ab ca"><div class="ch bg fy fz ga gb"></div></div></div><div class="ab ca"><div class="ch bg fy fz ga gb"><div class="rj rk ab jk"><div class="qe ab"><a class="rl ax am ao" rel="noopener follow" href="https://medium.com/tag/llm?source=post_page-----c62f55af492d---------------llm-----------------"><div class="rm fi cw rn gd ro rp be b bf z bj rq">Llm</div></a></div><div class="qe ab"><a class="rl ax am ao" rel="noopener follow" href="https://medium.com/tag/chatgpt?source=post_page-----c62f55af492d---------------chatgpt-----------------"><div class="rm fi cw rn gd ro rp be b bf z bj rq">ChatGPT</div></a></div><div class="qe ab"><a class="rl ax am ao" rel="noopener follow" href="https://medium.com/tag/gpt?source=post_page-----c62f55af492d---------------gpt-----------------"><div class="rm fi cw rn gd ro rp be b bf z bj rq">Gpt</div></a></div><div class="qe ab"><a class="rl ax am ao" rel="noopener follow" href="https://medium.com/tag/deep-learning?source=post_page-----c62f55af492d---------------deep_learning-----------------"><div class="rm fi cw rn gd ro rp be b bf z bj rq">Deep Learning</div></a></div><div class="qe ab"><a class="rl ax am ao" rel="noopener follow" href="https://medium.com/tag/nlp?source=post_page-----c62f55af492d---------------nlp-----------------"><div class="rm fi cw rn gd ro rp be b bf z bj rq">NLP</div></a></div></div></div></div><div class="l"></div><footer class="rr rs rt ru rv rw rx ry rz ab q sa sb c"><div class="l ae"><div class="ab ca"><div class="ch bg fy fz ga gb"><div class="ab co sc"><div class="ab q kt"><div class="sd l"><span class="l se sf sg e d"><div class="ab q kt"><div class="pw-multi-vote-icon fi ku kv kw kx"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerClapButton" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc62f55af492d&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40baptisteloquette.entr%2Flangchain-arxiv-tutor-data-loading-c62f55af492d&amp;user=Baptiste+L.&amp;userId=7e94df6b7255&amp;source=-----c62f55af492d---------------------clap_footer-----------"><div><div class="bl" aria-hidden="false" aria-describedby="8" aria-labelledby="8"><div class="ky ao kz la lb lc am ld le lf kx"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lg lh li lj lk ll lm"><div><div class="bl" aria-hidden="false" aria-describedby="52" aria-labelledby="52"><p class="be b du z dt"><button class="af ag ah ai aj ak al am an ao ap aq ar as at xr lv">89<span class="l h g f sh si"></span></button></p></div></div></div></div></span><span class="l h g f sh si"><div class="ab q kt"><div class="pw-multi-vote-icon fi ku kv kw kx"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerClapButton" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fc62f55af492d&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40baptisteloquette.entr%2Flangchain-arxiv-tutor-data-loading-c62f55af492d&amp;user=Baptiste+L.&amp;userId=7e94df6b7255&amp;source=-----c62f55af492d---------------------clap_footer-----------"><div><div class="bl" aria-hidden="false" aria-describedby="9" aria-labelledby="9"><div class="ky ao kz la lb lc am ld le lf kx"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lg lh li lj lk ll lm"><div><div class="bl" aria-hidden="false" aria-describedby="54" aria-labelledby="54"><p class="be b du z dt"><button class="af ag ah ai aj ak al am an ao ap aq ar as at xr lv">89</button></p></div></div></div></div></span></div><div class="bp ab"><div><div class="bl" aria-hidden="false" aria-describedby="10" aria-labelledby="10"><button class="ao ky lq lr ab q fj ls lt" aria-label="responses"><svg width="24" height="24" viewBox="0 0 24 24" class="lp"><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b bf z dt"><span class="pw-responses-count lo lp">3</span></p></button></div></div></div></div><div class="ab q"><div class="rh l jh"><div><div class="bl" aria-hidden="false" aria-describedby="11" aria-labelledby="11"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerBookmarkButton" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fc62f55af492d&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40baptisteloquette.entr%2Flangchain-arxiv-tutor-data-loading-c62f55af492d&amp;source=--------------------------bookmark_footer-----------"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="dt lv" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="currentColor"></path></svg></a></span></div></div></div><div class="rh l jh"><div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bl" aria-hidden="false" aria-describedby="12" aria-labelledby="12"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="footerSocialShareButton" class="af fj ah ai aj ak al mc an ao ap ew md me lt mf"><svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path fill-rule="evenodd" clip-rule="evenodd" d="M15.22 4.93a.42.42 0 0 1-.12.13h.01a.45.45 0 0 1-.29.08.52.52 0 0 1-.3-.13L12.5 3v7.07a.5.5 0 0 1-.5.5.5.5 0 0 1-.5-.5V3.02l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.8a.42.42 0 0 1 .07.5zm-.1.14zm.88 2h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11a2 2 0 0 1-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.14c.1.1.15.22.15.35a.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9V8.96c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1z" fill="currentColor"></path></svg></button></div></div></div></div></div></div></div></div></div></footer><div class="sj sk sl sm sn l bw"><div class="ab ca"><div class="ch bg fy fz ga gb"><div class="ck ab so co"><div class="ab ip"><a rel="noopener follow" href="https://medium.com/@baptisteloquette.entr?source=post_page-----c62f55af492d--------------------------------"><div class="l sp sq bx sr it"><div class="l fi"><img alt="Baptiste L." class="l fc bx ss st cw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_jiwQ9IOKR15F1zwNKrN_Ow(1).png" width="72" height="72" loading="lazy"><div class="iu bx l ss st fr n iv fs"></div></div></div></a></div><div class="j i d"><div class="ab"><span><button class="be b bf z eo rm ep eq er es et eu ev ew ex ey ez su fa fb fc bl fd fe">Follow</button></span><div class="ds l"><div><div><div class="bl" aria-hidden="false" aria-describedby="186" aria-labelledby="186"><div class="l"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F16c558504712&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40baptisteloquette.entr%2Flangchain-arxiv-tutor-data-loading-c62f55af492d&amp;newsletterV3=7e94df6b7255&amp;newsletterV3Id=16c558504712&amp;user=Baptiste+L.&amp;userId=7e94df6b7255&amp;source=-----c62f55af492d---------------------subscribe_user-----------"><button class="be b bf z eo am ep eq er es et eu ev ew ex ey ez fa fb fc bl fd fe" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="xt sw sx"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5L19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class="ab cm co"><div class="l"><div class="ab q"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab q" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr?source=post_page-----c62f55af492d--------------------------------"><h2 class="pw-author-name be th ti tj tk bj"><span class="gm">Written by <!-- -->Baptiste L.</span></h2></a></div><div class="qe ab"><div class="l jh"><span class="pw-follower-count be b bf z bj"><a class="af ag ah ai aj ak al am an ao ap aq ar ja" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr/followers?source=post_page-----c62f55af492d--------------------------------">81 Followers</a></span></div></div><div class="qp l"><p class="be b bf z bj"><span class="gm">Passionated about Semantic Search, NLP, Deep Learning &amp; Graphs | 21</span></p></div></div><div class="h k"><div class="ab"><span><button class="be b bf z eo rm ep eq er es et eu ev ew ex ey ez su fa fb fc bl fd fe">Follow</button></span><div class="ds l"><div><div><div class="bl" aria-hidden="false" aria-describedby="187" aria-labelledby="187"><div class="l"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2F16c558504712&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40baptisteloquette.entr%2Flangchain-arxiv-tutor-data-loading-c62f55af492d&amp;newsletterV3=7e94df6b7255&amp;newsletterV3Id=16c558504712&amp;user=Baptiste+L.&amp;userId=7e94df6b7255&amp;source=-----c62f55af492d---------------------subscribe_user-----------"><button class="be b bf z eo am ep eq er es et eu ev ew ex ey ez fa fb fc bl fd fe" aria-label="Subscribe"><svg width="38" height="38" viewBox="0 0 38 38" fill="none" class="xt sw sx"><rect x="26.25" y="9.25" width="0.5" height="6.5" rx="0.25"></rect><rect x="29.75" y="12.25" width="0.5" height="6.5" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5L19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class="tl bg tm gu gv gw gx gy"></div></div></div><div class="ab ca"><div class="ch bg fy fz ga gb"><div class="xu xv l"><h2 class="be th iy z hd bj">More from Baptiste L.</h2></div><div class="xw ab kt jk xx xy xz ya yb yc yd ye yf yg yh yi yj yk yl"><div class="ym yn yo yp yq yr ys yt yu yv yw yx yy yz za zb zc zd ze zf zg"><div class="zh zi zj zk zl dv l"><article class="dv"><div class="dv rz l"><div class="bg dv"><div class="dv l"><div class="dv zm zn zo zp zq zr zs zt zu zv zw zx zy"><div class="zz"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="LangChain Arxiv Tutor : Long Text Summarization, RetrievalQA and Vector Databases" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr/langchain-arxiv-tutor-long-text-summarization-retrievalqa-and-vector-databases-6d5cb1dc7e14?source=author_recirc-----c62f55af492d----0---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><div class="abb abc abd abe abf"><img alt="LangChain Arxiv Tutor : Long Text Summarization, RetrievalQA and Vector Databases" class="bg abg abh abi abj bw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_UpAKNhJYTpaQ4eWJKzWeDQ(1).png" loading="lazy"></div></a></div><div class="aba ab ca cn"><div class="va vc abk abl abm ab q"><div class="rl l"><div><div class="bl" aria-hidden="false" aria-describedby="78" aria-labelledby="78"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr?source=author_recirc-----c62f55af492d----0---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><div class="l fi"><img alt="Baptiste L." class="l fc bx abn abo cw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_jiwQ9IOKR15F1zwNKrN_Ow(2).png" width="20" height="20" loading="lazy"><div class="fq bx l abn abo fr n ax fs"></div></div></a></div></div></div><div class="abp l"><div><div class="bl" aria-hidden="false" aria-describedby="79" aria-labelledby="79"><a class="af ag ah ai aj ak al am an ao ap aq ar ja ab q" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr?source=author_recirc-----c62f55af492d----0---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><p class="be b du z px abq pz qa abr qc abs qd bj">Baptiste L.</p></a></div></div></div></div><div class="abt abu abv abw abx aby abz aca acb acc l gm"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr/langchain-arxiv-tutor-long-text-summarization-retrievalqa-and-vector-databases-6d5cb1dc7e14?source=author_recirc-----c62f55af492d----0---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><div title="LangChain Arxiv Tutor : Long Text Summarization, RetrievalQA and Vector Databases"><h2 class="be hf nw ny acd ace nz oa oc acf acg od nf ach aci acj ack nj acl acm acn aco nn acp acq acr acs px pz qa qc qd bj">LangChain Arxiv Tutor&nbsp;: Long Text Summarization, RetrievalQA and Vector Databases</h2></div><div class="act l"><h3 class="be b iy z px py pz qa qb qc qd dt">In this second Article we will talk about Long Text Summarization, Semantic Search and populate a Vector Database.</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr/langchain-arxiv-tutor-long-text-summarization-retrievalqa-and-vector-databases-6d5cb1dc7e14?source=author_recirc-----c62f55af492d----0---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><span class="be b du z dt"><div class="ab q"><span>10 min read</span><span class="jb l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Jul 7, 2023</span></div></span></a><div class="acu acv acw acx acy l"><div class="ab co"><div class="am acz ada adb adc add ade adf adg adh adi ab q"><div class="ab q kt"><div class="pw-multi-vote-icon fi ku kv kw kx"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F6d5cb1dc7e14&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40baptisteloquette.entr%2Flangchain-arxiv-tutor-long-text-summarization-retrievalqa-and-vector-databases-6d5cb1dc7e14&amp;user=Baptiste+L.&amp;userId=7e94df6b7255&amp;source=-----6d5cb1dc7e14----0-----------------clap_footer----819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><div><div class="bl" aria-hidden="false" aria-describedby="80" aria-labelledby="80"><div class="ky ao kz la lb lc am ld le lf kx"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lg lh li lj lk ll lm"><div><div class="bl" aria-hidden="false" aria-describedby="163" aria-labelledby="163"><p class="be b du z dt"><button class="af ag ah ai aj ak al am an ao ap aq ar as at xr lv">103<span class="l h g f sh si"></span></button></p></div></div></div></div><div class="adj l"><div><div class="bl" aria-hidden="false" aria-describedby="81" aria-labelledby="81"><a class="af fj ah ky aj ak al lr an ao ap aq ar as at lq ab q ls lt" aria-label="responses" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr/langchain-arxiv-tutor-long-text-summarization-retrievalqa-and-vector-databases-6d5cb1dc7e14?responsesOpen=true&amp;sortBy=REVERSE_CHRON&amp;source=author_recirc-----c62f55af492d----0---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count lo lp">1</span></p></a></div></div></div></div><div class="ab q adk adl"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="82" aria-labelledby="82"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F6d5cb1dc7e14&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40baptisteloquette.entr%2Flangchain-arxiv-tutor-long-text-summarization-retrievalqa-and-vector-databases-6d5cb1dc7e14&amp;source=-----c62f55af492d----0-----------------bookmark_preview----819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="dt lv" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="currentColor"></path></svg></a></span></div></div></div></div></div></div><div class="j i d"><div class="tl bg tm ra"></div></div></div></div></div></div></div></article></div></div><div class="ym yn yo yp yq yr ys yt yu yv yw yx yy yz za zb zc zd ze zf zg"><div class="zh zi zj zk zl dv l"><article class="dv"><div class="dv rz l"><div class="bg dv"><div class="dv l"><div class="dv zm zn zo zp zq zr zs zt zu zv zw zx zy"><div class="zz"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Training a Contextual Compression Model" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr/training-a-contextual-compression-model-2490f974eecf?source=author_recirc-----c62f55af492d----1---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><div class="abb abc abd abe abf"><img alt="Training a Contextual Compression Model" class="bg abg abh abi abj bw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_HGPHixQi3Uusy4SAyH2Ifg.jpg" loading="lazy"></div></a></div><div class="aba ab ca cn"><div class="va vc abk abl abm ab q"><div class="rl l"><div><div class="bl" aria-hidden="false" aria-describedby="83" aria-labelledby="83"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr?source=author_recirc-----c62f55af492d----1---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><div class="l fi"><img alt="Baptiste L." class="l fc bx abn abo cw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_jiwQ9IOKR15F1zwNKrN_Ow(2).png" width="20" height="20" loading="lazy"><div class="fq bx l abn abo fr n ax fs"></div></div></a></div></div></div><div class="abp l"><div><div class="bl" aria-hidden="false" aria-describedby="84" aria-labelledby="84"><a class="af ag ah ai aj ak al am an ao ap aq ar ja ab q" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr?source=author_recirc-----c62f55af492d----1---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><p class="be b du z px abq pz qa abr qc abs qd bj">Baptiste L.</p></a></div></div></div></div><div class="abt abu abv abw abx aby abz aca acb acc l gm"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr/training-a-contextual-compression-model-2490f974eecf?source=author_recirc-----c62f55af492d----1---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><div title=""><h2 class="be hf nw ny acd ace nz oa oc acf acg od nf ach aci acj ack nj acl acm acn aco nn acp acq acr acs px pz qa qc qd bj">Training a Contextual Compression Model</h2></div><div class="act l"><h3 class="be b iy z px py pz qa qb qc qd dt">For  RAG, a Contextual Compression step can ameliorate the results in multiple ways&nbsp;:</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr/training-a-contextual-compression-model-2490f974eecf?source=author_recirc-----c62f55af492d----1---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><span class="be b du z dt"><div class="ab q"><span>4 min read</span><span class="jb l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Aug 28, 2023</span></div></span></a><div class="acu acv acw acx acy l"><div class="ab co"><div class="am acz ada adb adc add ade adf adg adh adi ab q"><div class="ab q kt"><div class="pw-multi-vote-icon fi ku kv kw kx"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F2490f974eecf&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40baptisteloquette.entr%2Ftraining-a-contextual-compression-model-2490f974eecf&amp;user=Baptiste+L.&amp;userId=7e94df6b7255&amp;source=-----2490f974eecf----1-----------------clap_footer----819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><div><div class="bl" aria-hidden="false" aria-describedby="85" aria-labelledby="85"><div class="ky ao kz la lb lc am ld le lf kx"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lg lh li lj lk ll lm"><div><div class="bl" aria-hidden="false" aria-describedby="165" aria-labelledby="165"><p class="be b du z dt"><button class="af ag ah ai aj ak al am an ao ap aq ar as at xr lv">22<span class="l h g f sh si"></span></button></p></div></div></div></div><div class="adj l"><div><div class="bl" aria-hidden="false" aria-describedby="86" aria-labelledby="86"><a class="af fj ah ky aj ak al lr an ao ap aq ar as at lq ab q ls lt" aria-label="responses" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr/training-a-contextual-compression-model-2490f974eecf?responsesOpen=true&amp;sortBy=REVERSE_CHRON&amp;source=author_recirc-----c62f55af492d----1---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count lo lp">1</span></p></a></div></div></div></div><div class="ab q adk adl"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="87" aria-labelledby="87"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2490f974eecf&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40baptisteloquette.entr%2Ftraining-a-contextual-compression-model-2490f974eecf&amp;source=-----c62f55af492d----1-----------------bookmark_preview----819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="dt lv" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="currentColor"></path></svg></a></span></div></div></div></div></div></div><div class="j i d"><div class="tl bg tm ra"></div></div></div></div></div></div></div></article></div></div><div class="ym yn yo yp yq yr ys yt yu yv yw yx yy yz za zb zc zd ze zf zg"><div class="zh zi zj zk zl dv l"><article class="dv"><div class="dv rz l"><div class="bg dv"><div class="dv l"><div class="dv zm zn zo zp zq zr zs zt zu zv zw zx zy"><div class="zz"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Training a Retriever on Synthetic Data" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr/training-a-retriever-on-synthetic-data-1ab36026556e?source=author_recirc-----c62f55af492d----2---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><div class="abb abc abd abe abf"><img alt="Training a Retriever on Synthetic Data" class="bg abg abh abi abj bw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_HGPHixQi3Uusy4SAyH2Ifg.jpg" loading="lazy"></div></a></div><div class="aba ab ca cn"><div class="va vc abk abl abm ab q"><div class="rl l"><div><div class="bl" aria-hidden="false" aria-describedby="88" aria-labelledby="88"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr?source=author_recirc-----c62f55af492d----2---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><div class="l fi"><img alt="Baptiste L." class="l fc bx abn abo cw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_jiwQ9IOKR15F1zwNKrN_Ow(2).png" width="20" height="20" loading="lazy"><div class="fq bx l abn abo fr n ax fs"></div></div></a></div></div></div><div class="abp l"><div><div class="bl" aria-hidden="false" aria-describedby="89" aria-labelledby="89"><a class="af ag ah ai aj ak al am an ao ap aq ar ja ab q" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr?source=author_recirc-----c62f55af492d----2---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><p class="be b du z px abq pz qa abr qc abs qd bj">Baptiste L.</p></a></div></div></div></div><div class="abt abu abv abw abx aby abz aca acb acc l gm"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr/training-a-retriever-on-synthetic-data-1ab36026556e?source=author_recirc-----c62f55af492d----2---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><div title=""><h2 class="be hf nw ny acd ace nz oa oc acf acg od nf ach aci acj ack nj acl acm acn aco nn acp acq acr acs px pz qa qc qd bj">Training a Retriever on Synthetic Data</h2></div><div class="act l"><h3 class="be b iy z px py pz qa qb qc qd dt">Today we are going to use the previously generated synthetic queries to train a retriever on specific type of documents.</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr/training-a-retriever-on-synthetic-data-1ab36026556e?source=author_recirc-----c62f55af492d----2---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><span class="be b du z dt"><div class="ab q"><span>6 min read</span><span class="jb l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Aug 24, 2023</span></div></span></a><div class="acu acv acw acx acy l"><div class="ab co"><div class="am acz ada adb adc add ade adf adg adh adi ab q"><div class="ab q kt"><div class="pw-multi-vote-icon fi ku kv kw kx"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F1ab36026556e&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40baptisteloquette.entr%2Ftraining-a-retriever-on-synthetic-data-1ab36026556e&amp;user=Baptiste+L.&amp;userId=7e94df6b7255&amp;source=-----1ab36026556e----2-----------------clap_footer----819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><div><div class="bl" aria-hidden="false" aria-describedby="90" aria-labelledby="90"><div class="ky ao kz la lb lc am ld le lf kx"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lg lh li lj lk ll lm"><div><div class="bl" aria-hidden="false" aria-describedby="167" aria-labelledby="167"><p class="be b du z dt"><button class="af ag ah ai aj ak al am an ao ap aq ar as at xr lv">20<span class="l h g f sh si"></span></button></p></div></div></div></div><div class="adj l"><div><div class="bl" aria-hidden="false" aria-describedby="91" aria-labelledby="91"><a class="af fj ah ky aj ak al lr an ao ap aq ar as at lq ab q ls lt" aria-label="responses" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr/training-a-retriever-on-synthetic-data-1ab36026556e?responsesOpen=true&amp;sortBy=REVERSE_CHRON&amp;source=author_recirc-----c62f55af492d----2---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg></a></div></div></div></div><div class="ab q adk adl"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="92" aria-labelledby="92"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1ab36026556e&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40baptisteloquette.entr%2Ftraining-a-retriever-on-synthetic-data-1ab36026556e&amp;source=-----c62f55af492d----2-----------------bookmark_preview----819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="dt lv" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="currentColor"></path></svg></a></span></div></div></div></div></div></div><div class="j i d"><div class="tl bg tm ra"></div></div></div></div></div></div></div></article></div></div><div class="ym yn yo yp yq yr ys yt yu yv yw yx yy yz za zb zc zd ze zf zg"><div class="zh zi zj zk zl dv l"><article class="dv"><div class="dv rz l"><div class="bg dv"><div class="dv l"><div class="dv zm zn zo zp zq zr zs zt zu zv zw zx zy"><div class="zz"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="SPARSIFY IT : Block Sparse Lottery Tickets Hypothesis Pruning — NNs Sparsification Part 1" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr/sparsify-it-block-sparse-lottery-tickets-hypothesis-pruning-nns-sparsification-part-1-38d26b8550db?source=author_recirc-----c62f55af492d----3---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><div class="abb abc abd abe abf"><img alt="SPARSIFY IT : Block Sparse Lottery Tickets Hypothesis Pruning — NNs Sparsification Part 1" class="bg abg abh abi abj bw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_yWQol4hOVYMPajUOJPrMYw.png" loading="lazy"></div></a></div><div class="aba ab ca cn"><div class="va vc abk abl abm ab q"><div class="rl l"><div><div class="bl" aria-hidden="false" aria-describedby="93" aria-labelledby="93"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr?source=author_recirc-----c62f55af492d----3---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><div class="l fi"><img alt="Baptiste L." class="l fc bx abn abo cw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_jiwQ9IOKR15F1zwNKrN_Ow(2).png" width="20" height="20" loading="lazy"><div class="fq bx l abn abo fr n ax fs"></div></div></a></div></div></div><div class="abp l"><div><div class="bl" aria-hidden="false" aria-describedby="94" aria-labelledby="94"><a class="af ag ah ai aj ak al am an ao ap aq ar ja ab q" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr?source=author_recirc-----c62f55af492d----3---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><p class="be b du z px abq pz qa abr qc abs qd bj">Baptiste L.</p></a></div></div></div></div><div class="abt abu abv abw abx aby abz aca acb acc l gm"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr/sparsify-it-block-sparse-lottery-tickets-hypothesis-pruning-nns-sparsification-part-1-38d26b8550db?source=author_recirc-----c62f55af492d----3---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><div title="SPARSIFY IT : Block Sparse Lottery Tickets Hypothesis Pruning — NNs Sparsification Part 1"><h2 class="be hf nw ny acd ace nz oa oc acf acg od nf ach aci acj ack nj acl acm acn aco nn acp acq acr acs px pz qa qc qd bj">SPARSIFY IT&nbsp;: Block Sparse Lottery Tickets Hypothesis Pruning — NNs Sparsification Part 1</h2></div><div class="act l"><h3 class="be b iy z px py pz qa qb qc qd dt">Sparsity got a lot of Attention lately, through Sparse MoEs &amp; the release of Mixtral, and through Pruning technics. While the motivation…</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr/sparsify-it-block-sparse-lottery-tickets-hypothesis-pruning-nns-sparsification-part-1-38d26b8550db?source=author_recirc-----c62f55af492d----3---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><span class="be b du z dt"><div class="ab q"><span>8 min read</span><span class="jb l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Mar 2, 2024</span></div></span></a><div class="acu acv acw acx acy l"><div class="ab co"><div class="am acz ada adb adc add ade adf adg adh adi ab q"><div class="ab q kt"><div class="pw-multi-vote-icon fi ku kv kw kx"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F38d26b8550db&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40baptisteloquette.entr%2Fsparsify-it-block-sparse-lottery-tickets-hypothesis-pruning-nns-sparsification-part-1-38d26b8550db&amp;user=Baptiste+L.&amp;userId=7e94df6b7255&amp;source=-----38d26b8550db----3-----------------clap_footer----819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><div><div class="bl" aria-hidden="false" aria-describedby="95" aria-labelledby="95"><div class="ky ao kz la lb lc am ld le lf kx"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lg lh li lj lk ll lm"><div><div class="bl" aria-hidden="false" aria-describedby="169" aria-labelledby="169"><p class="be b du z dt"><button class="af ag ah ai aj ak al am an ao ap aq ar as at xr lv">71<span class="l h g f sh si"></span></button></p></div></div></div></div><div class="adj l"><div><div class="bl" aria-hidden="false" aria-describedby="96" aria-labelledby="96"><a class="af fj ah ky aj ak al lr an ao ap aq ar as at lq ab q ls lt" aria-label="responses" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr/sparsify-it-block-sparse-lottery-tickets-hypothesis-pruning-nns-sparsification-part-1-38d26b8550db?responsesOpen=true&amp;sortBy=REVERSE_CHRON&amp;source=author_recirc-----c62f55af492d----3---------------------819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count lo lp">1</span></p></a></div></div></div></div><div class="ab q adk adl"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="97" aria-labelledby="97"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F38d26b8550db&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40baptisteloquette.entr%2Fsparsify-it-block-sparse-lottery-tickets-hypothesis-pruning-nns-sparsification-part-1-38d26b8550db&amp;source=-----c62f55af492d----3-----------------bookmark_preview----819b45b6_208d_4346_b6e2_93ba34b38a9e-------"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="dt lv" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="currentColor"></path></svg></a></span></div></div></div></div></div></div></div></div></div></div></div></article></div></div></div><div class="tl bg tm dj dk adm adn ado"></div><div class="ab ji jj adp adq adr"><a class="be b bf z bj rm ads adt adu lv ls wr eu ev ew adv adw adx ez wc wd ady adz aea fa fb fc bl fd fe" rel="noopener follow" href="https://medium.com/@baptisteloquette.entr?source=post_page-----c62f55af492d--------------------------------"><div class="l fe">See all from Baptiste L.</div></a></div></div></div><div class="tl bg tm aeb aec aed aee aef"></div><div class="ab ca"><div class="ch bg fy fz ga gb"><div class="aeg aeh l"><h2 class="be th nw ny nz oa oc od oe og oh oi ok ol om oo op bj">Recommended from Medium</h2><div class="ow ox oy oz pa l"><div class="xw ab kt jk xx xy xz ya yb yc yd ye yf yg yh yi yj yk yl"><div class="ym yn yo yp yq yr ys yt yu yv yw yx yy yz za zb zc zd ze zf zg"><div class="zh zi zj zk zl dv l"><article class="dv"><div class="dv rz l"><div class="bg dv"><div class="dv l"><div class="dv zm zn zo zp zq zr zs zt zu zv zw zx zy"><div class="zz"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Extract custom table from PDF with LLMs" rel="noopener follow" href="https://medium.com/@knowledgrator/extract-custom-table-from-pdf-with-llms-2ad678c26200?source=read_next_recirc-----c62f55af492d----0---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div class="abb abc abd abe abf"><img alt="Extract custom table from PDF with LLMs" class="bg abg abh abi abj bw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/0_kHmeDrx5BoHskPUK.png" loading="lazy"></div></a></div><div class="aba ab ca cn"><div class="va vc abk abl abm ab q"><div class="rl l"><div><div class="bl" aria-hidden="false" aria-describedby="98" aria-labelledby="98"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@knowledgrator?source=read_next_recirc-----c62f55af492d----0---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div class="l fi"><img alt="Knowledgator Engineering" class="l fc bx abn abo cw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_aPHKY5EyhH--A6WP25y9kQ.png" width="20" height="20" loading="lazy"><div class="fq bx l abn abo fr n ax fs"></div></div></a></div></div></div><div class="abp l"><div><div class="bl" aria-hidden="false" aria-describedby="99" aria-labelledby="99"><a class="af ag ah ai aj ak al am an ao ap aq ar ja ab q" rel="noopener follow" href="https://medium.com/@knowledgrator?source=read_next_recirc-----c62f55af492d----0---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><p class="be b du z px abq pz qa abr qc abs qd bj">Knowledgator Engineering</p></a></div></div></div></div><div class="abt abu abv abw abx aby abz aca acb acc l gm"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/@knowledgrator/extract-custom-table-from-pdf-with-llms-2ad678c26200?source=read_next_recirc-----c62f55af492d----0---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div title=""><h2 class="be hf nw ny acd ace nz oa oc acf acg od nf ach aci acj ack nj acl acm acn aco nn acp acq acr acs px pz qa qc qd bj">Extract custom table from PDF with LLMs</h2></div><div class="act l"><h3 class="be b iy z px py pz qa qb qc qd dt">Portable Document Format (PDF) is one of the most widely used file formats for sharing information, especially in academic, scientific…</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/@knowledgrator/extract-custom-table-from-pdf-with-llms-2ad678c26200?source=read_next_recirc-----c62f55af492d----0---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><span class="be b du z dt"><div class="ab q"><span>5 min read</span><span class="jb l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Sep 30, 2023</span></div></span></a><div class="acu acv acw acx acy l"><div class="ab co"><div class="am acz ada adb adc add ade adf adg adh adi ab q"><div class="ab q kt"><div class="pw-multi-vote-icon fi ku kv kw kx"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F2ad678c26200&amp;operation=register&amp;redirect=https%3A%2F%2Fblog.knowledgator.com%2Fextract-custom-table-from-pdf-with-llms-2ad678c26200&amp;user=Knowledgator+Engineering&amp;userId=2306e589837&amp;source=-----2ad678c26200----0-----------------clap_footer----d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div><div class="bl" aria-hidden="false" aria-describedby="100" aria-labelledby="100"><div class="ky ao kz la lb lc am ld le lf kx"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lg lh li lj lk ll lm"><div><div class="bl" aria-hidden="false" aria-describedby="171" aria-labelledby="171"><p class="be b du z dt"><button class="af ag ah ai aj ak al am an ao ap aq ar as at xr lv">631<span class="l h g f sh si"></span></button></p></div></div></div></div><div class="adj l"><div><div class="bl" aria-hidden="false" aria-describedby="101" aria-labelledby="101"><a class="af fj ah ky aj ak al lr an ao ap aq ar as at lq ab q ls lt" aria-label="responses" rel="noopener follow" href="https://medium.com/@knowledgrator/extract-custom-table-from-pdf-with-llms-2ad678c26200?responsesOpen=true&amp;sortBy=REVERSE_CHRON&amp;source=read_next_recirc-----c62f55af492d----0---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count lo lp">2</span></p></a></div></div></div></div><div class="ab q adk adl"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="102" aria-labelledby="102"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F2ad678c26200&amp;operation=register&amp;redirect=https%3A%2F%2Fblog.knowledgator.com%2Fextract-custom-table-from-pdf-with-llms-2ad678c26200&amp;source=-----c62f55af492d----0-----------------bookmark_preview----d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="dt lv" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="currentColor"></path></svg></a></span></div></div></div></div></div></div><div class="j i d"><div class="tl bg tm ra"></div></div></div></div></div></div></div></article></div></div><div class="ym yn yo yp yq yr ys yt yu yv yw yx yy yz za zb zc zd ze zf zg"><div class="zh zi zj zk zl dv l"><article class="dv"><div class="dv rz l"><div class="bg dv"><div class="dv l"><div class="dv zm zn zo zp zq zr zs zt zu zv zw zx zy"><div class="zz"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Unraveling the layout of a PDF file with computer vision techniques" rel="noopener follow" href="https://medium.com/@prudant/unraveling-the-layout-of-a-pdf-file-with-computer-vision-techniques-1afdc5e53d62?source=read_next_recirc-----c62f55af492d----1---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div class="abb abc abd abe abf"><img alt="Unraveling the layout of a PDF file with computer vision techniques" class="bg abg abh abi abj bw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_PWSkIcsd8ZL2l_B-qFMn9Q.png" loading="lazy"></div></a></div><div class="aba ab ca cn"><div class="va vc abk abl abm ab q"><div class="rl l"><div><div class="bl" aria-hidden="false" aria-describedby="103" aria-labelledby="103"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@prudant?source=read_next_recirc-----c62f55af492d----1---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div class="l fi"><img alt="Darío Andrés Muñoz Prudant" class="l fc bx abn abo cw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_JimyKm_JcKJYaubWBVuXjw.png" width="20" height="20" loading="lazy"><div class="fq bx l abn abo fr n ax fs"></div></div></a></div></div></div><div class="abp l"><div><div class="bl" aria-hidden="false" aria-describedby="104" aria-labelledby="104"><a class="af ag ah ai aj ak al am an ao ap aq ar ja ab q" rel="noopener follow" href="https://medium.com/@prudant?source=read_next_recirc-----c62f55af492d----1---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><p class="be b du z px abq pz qa abr qc abs qd bj">Darío Andrés Muñoz Prudant</p></a></div></div></div></div><div class="abt abu abv abw abx aby abz aca acb acc l gm"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/@prudant/unraveling-the-layout-of-a-pdf-file-with-computer-vision-techniques-1afdc5e53d62?source=read_next_recirc-----c62f55af492d----1---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div title=""><h2 class="be hf nw ny acd ace nz oa oc acf acg od nf ach aci acj ack nj acl acm acn aco nn acp acq acr acs px pz qa qc qd bj">Unraveling the layout of a PDF file with computer vision techniques</h2></div><div class="act l"><h3 class="be b iy z px py pz qa qb qc qd dt">Introduction</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/@prudant/unraveling-the-layout-of-a-pdf-file-with-computer-vision-techniques-1afdc5e53d62?source=read_next_recirc-----c62f55af492d----1---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><span class="be b du z dt"><div class="ab q"><span>9 min read</span><span class="jb l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Nov 11, 2023</span></div></span></a><div class="acu acv acw acx acy l"><div class="ab co"><div class="am acz ada adb adc add ade adf adg adh adi ab q"><div class="ab q kt"><div class="pw-multi-vote-icon fi ku kv kw kx"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F1afdc5e53d62&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40prudant%2Funraveling-the-layout-of-a-pdf-file-with-computer-vision-techniques-1afdc5e53d62&amp;user=Dar%C3%ADo+Andr%C3%A9s+Mu%C3%B1oz+Prudant&amp;userId=98dbc610ea82&amp;source=-----1afdc5e53d62----1-----------------clap_footer----d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div><div class="bl" aria-hidden="false" aria-describedby="105" aria-labelledby="105"><div class="ky ao kz la lb lc am ld le lf kx"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lg lh li lj lk ll lm"><div><div class="bl" aria-hidden="false" aria-describedby="173" aria-labelledby="173"><p class="be b du z dt"><button class="af ag ah ai aj ak al am an ao ap aq ar as at xr lv">5<span class="l h g f sh si"></span></button></p></div></div></div></div><div class="adj l"><div><div class="bl" aria-hidden="false" aria-describedby="106" aria-labelledby="106"><a class="af fj ah ky aj ak al lr an ao ap aq ar as at lq ab q ls lt" aria-label="responses" rel="noopener follow" href="https://medium.com/@prudant/unraveling-the-layout-of-a-pdf-file-with-computer-vision-techniques-1afdc5e53d62?responsesOpen=true&amp;sortBy=REVERSE_CHRON&amp;source=read_next_recirc-----c62f55af492d----1---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count lo lp">1</span></p></a></div></div></div></div><div class="ab q adk adl"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="107" aria-labelledby="107"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F1afdc5e53d62&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40prudant%2Funraveling-the-layout-of-a-pdf-file-with-computer-vision-techniques-1afdc5e53d62&amp;source=-----c62f55af492d----1-----------------bookmark_preview----d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="dt lv" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="currentColor"></path></svg></a></span></div></div></div></div></div></div></div></div></div></div></div></article></div></div></div></div><div class="tl bg tm aei"></div><h2 class="be th iy z hd bj">Lists</h2><div class="ra l"><div class="cm ab kt jk xx xy xz ya yb yc yd ye yf yg yh yi yj yk yl"><div class="ym yn yo yp yq yr ys yt yu yv yw yx yy yz za zb zc zd ze zf zg"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" rel="noopener follow" href="https://medium.com/@MediumStaff/list/the-new-chatbots-chatgpt-bard-and-beyond-5969c7449b7f?source=read_next_recirc-----c62f55af492d--------------------------------"><div class="aep aeq px ab jh fi"><div class="fi abg aek bw ael"><div class="abg ir px l"><img alt="Image by vectorjuice on FreePik" class="" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/0_3OsUtsnlTx9Svm4c.jpg" width="48" height="48" loading="lazy"></div></div><div class="fi abg aek bw aem aen"><div class="abg ir px l"><img alt="" class="" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_IPZF1hcDWwpPqOz2vL7NxQ.png" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="fi abg bw sb aeo"><div class="abg ir px l"><img alt="" class="" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_0fHUKyg3xtpNWpop35PR4g.png" width="48" height="48" loading="lazy" role="presentation"></div></div></div><div class="aw l"><h2 class="be th iy z px py pz qa qb qc qd hd bj">The New Chatbots: ChatGPT, Bard, and Beyond</h2><div class="be b du z dt ab aej">12 stories<span class="jb l" aria-hidden="true"><span class="be b bf z dt">·</span></span>334 saves</div></div></a></div><div class="ym yn yo yp yq yr ys yt yu yv yw yx yy yz za zb zc zd ze zf zg"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" rel="noopener follow" href="https://medium.com/@MediumForTeams/list/what-is-chatgpt-7a5756752f49?source=read_next_recirc-----c62f55af492d--------------------------------"><div class="aep aeq px ab jh fi"><div class="fi abg aek bw ael"><div class="abg ir px l"><img alt="" class="" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/0__eYHSSUS0abUxmDU.jpg" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="fi abg aek bw aem aen"><div class="abg ir px l"><img alt="" class="" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_wXgeNtz5OJ5O9T3c3mQRRw.png" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="fi abg bw sb aeo"><div class="abg ir px l"><img alt="" class="" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/0_tIipcmrInD5UMpQI.jpg" width="48" height="48" loading="lazy" role="presentation"></div></div></div><div class="aw l"><h2 class="be th iy z px py pz qa qb qc qd hd bj">What is ChatGPT?</h2><div class="be b du z dt ab aej">9 stories<span class="jb l" aria-hidden="true"><span class="be b bf z dt">·</span></span>320 saves</div></div></a></div><div class="ym yn yo yp yq yr ys yt yu yv yw yx yy yz za zb zc zd ze zf zg"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" rel="noopener follow" href="https://medium.com/@nicholas.michael.janulewicz/list/chatgpt-prompts-b4c47b8e12ee?source=read_next_recirc-----c62f55af492d--------------------------------"><div class="aep aeq px ab jh fi"><div class="fi abg aek bw ael"><div class="abg ir px l"><img alt="" class="" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_rA5T3ZTDMr3Gh0taL6-CGA.png" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="fi abg aek bw aem aen"><div class="abg ir px l"><img alt="" class="" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_9l0iePJqhp93hXlEupk27A.png" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="fi abg bw sb aeo"><div class="abg ir px l"><img alt="" class="" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_3CpH1U4LpX8jcrpOPdGSYQ.png" width="48" height="48" loading="lazy" role="presentation"></div></div></div><div class="aw l"><h2 class="be th iy z px py pz qa qb qc qd hd bj">ChatGPT prompts </h2><div class="be b du z dt ab aej">47 stories<span class="jb l" aria-hidden="true"><span class="be b bf z dt">·</span></span>1267 saves</div></div></a></div><div class="ym yn yo yp yq yr ys yt yu yv yw yx yy yz za zb zc zd ze zf zg"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab ck cm" rel="noopener follow" href="https://medium.com/@m.wasalski/list/chatgpt-3742c7a4727d?source=read_next_recirc-----c62f55af492d--------------------------------"><div class="aep aeq px ab jh fi"><div class="fi abg aek bw ael"><div class="abg ir px l"><img alt="" class="" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_vzu3JPzaq2EZKTZNY9BhLA.png" width="48" height="48" loading="lazy" role="presentation"></div></div><div class="fi abg aek bw aem aen"><div class="abg ir px l"><img alt="AI-generated image of a cute tiny robot in the backdrop of ChatGPT’s logo" class="" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_lEmL62oZdrOOWIzAAFKiFg.jpg" width="48" height="48" loading="lazy"></div></div><div class="fi abg bw sb aeo"><div class="abg ir px l"><img alt="" class="" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_i2zLIwC9mftamP1dbciCeQ.jpg" width="48" height="48" loading="lazy" role="presentation"></div></div></div><div class="aw l"><h2 class="be th iy z px py pz qa qb qc qd hd bj">ChatGPT</h2><div class="be b du z dt ab aej">21 stories<span class="jb l" aria-hidden="true"><span class="be b bf z dt">·</span></span>520 saves</div></div></a></div></div></div><div class="tl bg tm aer dj aes dk aet aeu aev aew aex aey"></div><div class="xw ab kt jk xx xy xz ya yb yc yd ye yf yg yh yi yj yk yl"><div class="ym yn yo yp yq yr ys yt yu yv yw yx yy yz za zb zc zd ze zf zg"><div class="zh zi zj zk zl dv l"><article class="dv"><div class="dv rz l"><div class="bg dv"><div class="dv l"><div class="dv zm zn zo zp zq zr zs zt zu zv zw zx zy"><div class="zz"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Rapid Q&amp;A on multiple PDFs using langchain and chromadb as local disk vector store" rel="noopener follow" href="https://medium.com/@diptimanrc/rapid-q-a-on-multiple-pdfs-using-langchain-and-chromadb-as-local-disk-vector-store-60678328c0df?source=read_next_recirc-----c62f55af492d----0---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div class="abb abc abd abe abf"><img alt="Rapid Q&amp;A on multiple PDFs using langchain and chromadb as local disk vector store" class="bg abg abh abi abj bw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_VY8ZP-pdz8C77FtNOORJRQ.png" loading="lazy"></div></a></div><div class="aba ab ca cn"><div class="va vc abk abl abm ab q"><div class="rl l"><div><div class="bl" aria-hidden="false" aria-describedby="108" aria-labelledby="108"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@diptimanrc?source=read_next_recirc-----c62f55af492d----0---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div class="l fi"><img alt="Diptiman Raichaudhuri" class="l fc bx abn abo cw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_rWkzj3YUa6lx12WNxF5Tjw.jpg" width="20" height="20" loading="lazy"><div class="fq bx l abn abo fr n ax fs"></div></div></a></div></div></div><div class="abp l"><div><div class="bl" aria-hidden="false" aria-describedby="109" aria-labelledby="109"><a class="af ag ah ai aj ak al am an ao ap aq ar ja ab q" rel="noopener follow" href="https://medium.com/@diptimanrc?source=read_next_recirc-----c62f55af492d----0---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><p class="be b du z px abq pz qa abr qc abs qd bj">Diptiman Raichaudhuri</p></a></div></div></div></div><div class="abt abu abv abw abx aby abz aca acb acc l gm"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/@diptimanrc/rapid-q-a-on-multiple-pdfs-using-langchain-and-chromadb-as-local-disk-vector-store-60678328c0df?source=read_next_recirc-----c62f55af492d----0---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div title="Rapid Q&amp;A on multiple PDFs using langchain and chromadb as local disk vector store"><h2 class="be hf nw ny acd ace nz oa oc acf acg od nf ach aci acj ack nj acl acm acn aco nn acp acq acr acs px pz qa qc qd bj">Rapid Q&amp;A on multiple PDFs using langchain and chromadb as local disk vector store</h2></div><div class="act l"><h3 class="be b iy z px py pz qa qb qc qd dt">Disclosure: All opinions expressed in this article are my own, and represent no one but myself and not those of my current or any previous…</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/@diptimanrc/rapid-q-a-on-multiple-pdfs-using-langchain-and-chromadb-as-local-disk-vector-store-60678328c0df?source=read_next_recirc-----c62f55af492d----0---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><span class="be b du z dt"><div class="ab q"><span>11 min read</span><span class="jb l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Sep 25, 2023</span></div></span></a><div class="acu acv acw acx acy l"><div class="ab co"><div class="am acz ada adb adc add ade adf adg adh adi ab q"><div class="ab q kt"><div class="pw-multi-vote-icon fi ku kv kw kx"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2F60678328c0df&amp;operation=register&amp;redirect=https%3A%2F%2Fdiptimanrc.medium.com%2Frapid-q-a-on-multiple-pdfs-using-langchain-and-chromadb-as-local-disk-vector-store-60678328c0df&amp;user=Diptiman+Raichaudhuri&amp;userId=c12cd47b94c9&amp;source=-----60678328c0df----0-----------------clap_footer----d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div><div class="bl" aria-hidden="false" aria-describedby="110" aria-labelledby="110"><div class="ky ao kz la lb lc am ld le lf kx"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lg lh li lj lk ll lm"><div><div class="bl" aria-hidden="false" aria-describedby="175" aria-labelledby="175"><p class="be b du z dt"><button class="af ag ah ai aj ak al am an ao ap aq ar as at xr lv">136<span class="l h g f sh si"></span></button></p></div></div></div></div><div class="adj l"><div><div class="bl" aria-hidden="false" aria-describedby="111" aria-labelledby="111"><a class="af fj ah ky aj ak al lr an ao ap aq ar as at lq ab q ls lt" aria-label="responses" rel="noopener follow" href="https://medium.com/@diptimanrc/rapid-q-a-on-multiple-pdfs-using-langchain-and-chromadb-as-local-disk-vector-store-60678328c0df?responsesOpen=true&amp;sortBy=REVERSE_CHRON&amp;source=read_next_recirc-----c62f55af492d----0---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count lo lp">6</span></p></a></div></div></div></div><div class="ab q adk adl"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="112" aria-labelledby="112"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F60678328c0df&amp;operation=register&amp;redirect=https%3A%2F%2Fdiptimanrc.medium.com%2Frapid-q-a-on-multiple-pdfs-using-langchain-and-chromadb-as-local-disk-vector-store-60678328c0df&amp;source=-----c62f55af492d----0-----------------bookmark_preview----d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="dt lv" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="currentColor"></path></svg></a></span></div></div></div></div></div></div><div class="j i d"><div class="tl bg tm ra"></div></div></div></div></div></div></div></article></div></div><div class="ym yn yo yp yq yr ys yt yu yv yw yx yy yz za zb zc zd ze zf zg"><div class="zh zi zj zk zl dv l"><article class="dv"><div class="dv rz l"><div class="bg dv"><div class="dv l"><div class="dv zm zn zo zp zq zr zs zt zu zv zw zx zy"><div class="zz"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Extracting text from PDF files with Python: A comprehensive guide" rel="noopener follow" href="https://medium.com/towards-data-science/extracting-text-from-pdf-files-with-python-a-comprehensive-guide-9fc4003d517?source=read_next_recirc-----c62f55af492d----1---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div class="abb abc abd abe abf"><img alt="Extracting text from PDF files with Python: A comprehensive guide" class="bg abg abh abi abj bw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/0_a77IsEM5jpM5YvmL.jpg" loading="lazy"></div></a></div><div class="aba ab ca cn"><div class="va vc abk abl abm ab q"><div class="rl l"><div><div class="bl" aria-hidden="false" aria-describedby="113" aria-labelledby="113"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@george.stavrakis.1996?source=read_next_recirc-----c62f55af492d----1---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div class="l fi"><img alt="George Stavrakis" class="l fc bx abn abo cw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_069U605RvPPcYHF4742cVA.jpg" width="20" height="20" loading="lazy"><div class="fq bx l abn abo fr n ax fs"></div></div></a></div></div></div><div class="abp l"><div><div class="bl" aria-hidden="false" aria-describedby="114" aria-labelledby="114"><a class="af ag ah ai aj ak al am an ao ap aq ar ja ab q" rel="noopener follow" href="https://medium.com/@george.stavrakis.1996?source=read_next_recirc-----c62f55af492d----1---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><p class="be b du z px abq pz qa abr qc abs qd bj">George Stavrakis</p></a></div></div></div><div class="abp l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false" aria-describedby="115" aria-labelledby="115"><a class="af ag ah ai aj ak al am an ao ap aq ar ja ab q" href="https://medium.com/towards-data-science?source=read_next_recirc-----c62f55af492d----1---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------" rel="noopener follow"><p class="be b du z px abq pz qa abr qc abs qd bj">Towards Data Science</p></a></div></div></div></div><div class="abt abu abv abw abx aby abz aca acb acc l gm"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/towards-data-science/extracting-text-from-pdf-files-with-python-a-comprehensive-guide-9fc4003d517?source=read_next_recirc-----c62f55af492d----1---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div title=""><h2 class="be hf nw ny acd ace nz oa oc acf acg od nf ach aci acj ack nj acl acm acn aco nn acp acq acr acs px pz qa qc qd bj">Extracting text from PDF files with Python: A comprehensive guide</h2></div><div class="act l"><h3 class="be b iy z px py pz qa qb qc qd dt">A complete process to extract textual information from tables, images, and plain text from a PDF file</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/towards-data-science/extracting-text-from-pdf-files-with-python-a-comprehensive-guide-9fc4003d517?source=read_next_recirc-----c62f55af492d----1---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><span class="be b du z dt"><div class="ab q"><div class="rz ab"><div class="bl" aria-hidden="false" aria-describedby="116" aria-labelledby="116"><button class="l ax ao am" aria-label="Member-only story"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="117" aria-labelledby="117"><svg width="16" height="16" viewBox="0 0 64 64" fill="none"><path d="M39.64 40.83L33.87 56.7a1.99 1.99 0 0 1-3.74 0l-5.77-15.87a2.02 2.02 0 0 0-1.2-1.2L7.3 33.88a1.99 1.99 0 0 1 0-3.74l15.87-5.77a2.02 2.02 0 0 0 1.2-1.2L30.12 7.3a1.99 1.99 0 0 1 3.74 0l5.77 15.87a2.02 2.02 0 0 0 1.2 1.2l15.86 5.76a1.99 1.99 0 0 1 0 3.74l-15.87 5.77a2.02 2.02 0 0 0-1.2 1.2z" fill="#FFC017"></path></svg></div></div></div></button></div></div><span class="jb l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>17 min read</span><span class="jb l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Sep 21, 2023</span></div></span></a><div class="acu acv acw acx acy l"><div class="ab co"><div class="am acz ada adb adc add ade adf adg adh adi ab q"><div class="ab q kt"><div class="pw-multi-vote-icon fi ku kv kw kx"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F9fc4003d517&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextracting-text-from-pdf-files-with-python-a-comprehensive-guide-9fc4003d517&amp;user=George+Stavrakis&amp;userId=fbbd4313532a&amp;source=-----9fc4003d517----1-----------------clap_footer----d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div><div class="bl" aria-hidden="false" aria-describedby="118" aria-labelledby="118"><div class="ky ao kz la lb lc am ld le lf kx"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lg lh li lj lk ll lm"><div><div class="bl" aria-hidden="false" aria-describedby="177" aria-labelledby="177"><p class="be b du z dt"><button class="af ag ah ai aj ak al am an ao ap aq ar as at xr lv">1.3K<span class="l h g f sh si"></span></button></p></div></div></div></div><div class="adj l"><div><div class="bl" aria-hidden="false" aria-describedby="119" aria-labelledby="119"><a class="af fj ah ky aj ak al lr an ao ap aq ar as at lq ab q ls lt" aria-label="responses" rel="noopener follow" href="https://medium.com/towards-data-science/extracting-text-from-pdf-files-with-python-a-comprehensive-guide-9fc4003d517?responsesOpen=true&amp;sortBy=REVERSE_CHRON&amp;source=read_next_recirc-----c62f55af492d----1---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count lo lp">24</span></p></a></div></div></div></div><div class="ab q adk adl"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="120" aria-labelledby="120"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F9fc4003d517&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fextracting-text-from-pdf-files-with-python-a-comprehensive-guide-9fc4003d517&amp;source=-----c62f55af492d----1-----------------bookmark_preview----d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="dt lv" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="currentColor"></path></svg></a></span></div></div></div></div></div></div><div class="j i d"><div class="tl bg tm ra"></div></div></div></div></div></div></div></article></div></div><div class="ym yn yo yp yq yr ys yt yu yv yw yx yy yz za zb zc zd ze zf zg"><div class="zh zi zj zk zl dv l"><article class="dv"><div class="dv rz l"><div class="bg dv"><div class="dv l"><div class="dv zm zn zo zp zq zr zs zt zu zv zw zx zy"><div class="zz"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="Chat GPT output mentioning the necessity of an efficient parser" rel="noopener follow" href="https://medium.com/llamaindex-blog/mastering-pdfs-extracting-sections-headings-paragraphs-and-tables-with-cutting-edge-parser-faea18870125?source=read_next_recirc-----c62f55af492d----2---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div class="abb abc abd abe abf"><img alt="Chat GPT output mentioning the necessity of an efficient parser" class="bg abg abh abi abj bw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_3X_McbzikW3Uty6qaQKYgw.jpg" loading="lazy"></div></a></div><div class="aba ab ca cn"><div class="va vc abk abl abm ab q"><div class="rl l"><div><div class="bl" aria-hidden="false" aria-describedby="121" aria-labelledby="121"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@kirankurup?source=read_next_recirc-----c62f55af492d----2---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div class="l fi"><img alt="Kiran Neelakanda Panicker" class="l fc bx abn abo cw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_-QRF-e6LE2Z6iG7exhjd3Q.jpg" width="20" height="20" loading="lazy"><div class="fq bx l abn abo fr n ax fs"></div></div></a></div></div></div><div class="abp l"><div><div class="bl" aria-hidden="false" aria-describedby="122" aria-labelledby="122"><a class="af ag ah ai aj ak al am an ao ap aq ar ja ab q" rel="noopener follow" href="https://medium.com/@kirankurup?source=read_next_recirc-----c62f55af492d----2---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><p class="be b du z px abq pz qa abr qc abs qd bj">Kiran Neelakanda Panicker</p></a></div></div></div><div class="abp l"><p class="be b du z dt">in</p></div><div class="l"><div><div class="bl" aria-hidden="false" aria-describedby="123" aria-labelledby="123"><a class="af ag ah ai aj ak al am an ao ap aq ar ja ab q" href="https://medium.com/llamaindex-blog?source=read_next_recirc-----c62f55af492d----2---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------" rel="noopener follow"><p class="be b du z px abq pz qa abr qc abs qd bj">LlamaIndex Blog</p></a></div></div></div></div><div class="abt abu abv abw abx aby abz aca acb acc l gm"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/llamaindex-blog/mastering-pdfs-extracting-sections-headings-paragraphs-and-tables-with-cutting-edge-parser-faea18870125?source=read_next_recirc-----c62f55af492d----2---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div title="Mastering PDFs: Extracting Sections, Headings, Paragraphs, and Tables with Cutting-Edge Parser"><h2 class="be hf nw ny acd ace nz oa oc acf acg od nf ach aci acj ack nj acl acm acn aco nn acp acq acr acs px pz qa qc qd bj">Mastering PDFs: Extracting Sections, Headings, Paragraphs, and Tables with Cutting-Edge Parser</h2></div><div class="act l"><h3 class="be b iy z px py pz qa qb qc qd dt">Despite recent motivation to utilize NLP for wider range of real world applications, most NLP papers, tasks and pipelines assume raw, clean…</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/llamaindex-blog/mastering-pdfs-extracting-sections-headings-paragraphs-and-tables-with-cutting-edge-parser-faea18870125?source=read_next_recirc-----c62f55af492d----2---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><span class="be b du z dt"><div class="ab q"><span>5 min read</span><span class="jb l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Oct 18, 2023</span></div></span></a><div class="acu acv acw acx acy l"><div class="ab co"><div class="am acz ada adb adc add ade adf adg adh adi ab q"><div class="ab q kt"><div class="pw-multi-vote-icon fi ku kv kw kx"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fllamaindex-blog%2Ffaea18870125&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fllamaindex-blog%2Fmastering-pdfs-extracting-sections-headings-paragraphs-and-tables-with-cutting-edge-parser-faea18870125&amp;user=Kiran+Neelakanda+Panicker&amp;userId=f08ed8ec35ad&amp;source=-----faea18870125----2-----------------clap_footer----d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div><div class="bl" aria-hidden="false" aria-describedby="124" aria-labelledby="124"><div class="ky ao kz la lb lc am ld le lf kx"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lg lh li lj lk ll lm"><div><div class="bl" aria-hidden="false" aria-describedby="179" aria-labelledby="179"><p class="be b du z dt"><button class="af ag ah ai aj ak al am an ao ap aq ar as at xr lv">889<span class="l h g f sh si"></span></button></p></div></div></div></div><div class="adj l"><div><div class="bl" aria-hidden="false" aria-describedby="125" aria-labelledby="125"><a class="af fj ah ky aj ak al lr an ao ap aq ar as at lq ab q ls lt" aria-label="responses" rel="noopener follow" href="https://medium.com/llamaindex-blog/mastering-pdfs-extracting-sections-headings-paragraphs-and-tables-with-cutting-edge-parser-faea18870125?responsesOpen=true&amp;sortBy=REVERSE_CHRON&amp;source=read_next_recirc-----c62f55af492d----2---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count lo lp">13</span></p></a></div></div></div></div><div class="ab q adk adl"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="126" aria-labelledby="126"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ffaea18870125&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fllamaindex-blog%2Fmastering-pdfs-extracting-sections-headings-paragraphs-and-tables-with-cutting-edge-parser-faea18870125&amp;source=-----c62f55af492d----2-----------------bookmark_preview----d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="dt lv" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="currentColor"></path></svg></a></span></div></div></div></div></div></div><div class="j i d"><div class="tl bg tm ra"></div></div></div></div></div></div></div></article></div></div><div class="ym yn yo yp yq yr ys yt yu yv yw yx yy yz za zb zc zd ze zf zg"><div class="zh zi zj zk zl dv l"><article class="dv"><div class="dv rz l"><div class="bg dv"><div class="dv l"><div class="dv zm zn zo zp zq zr zs zt zu zv zw zx zy"><div class="zz"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" aria-label="KTP-OCR in Python using Pytesseract" rel="noopener follow" href="https://medium.com/@firhanmaulanarusli/ktp-ocr-in-python-using-pytesseract-f079e8facd36?source=read_next_recirc-----c62f55af492d----3---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div class="abb abc abd abe abf"><img alt="KTP-OCR in Python using Pytesseract" class="bg abg abh abi abj bw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1__wRXJu7F9EQDnz1tSPVlLg.jpg" loading="lazy"></div></a></div><div class="aba ab ca cn"><div class="va vc abk abl abm ab q"><div class="rl l"><div><div class="bl" aria-hidden="false" aria-describedby="127" aria-labelledby="127"><a tabindex="-1" rel="noopener follow" href="https://medium.com/@firhanmaulanarusli?source=read_next_recirc-----c62f55af492d----3---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div class="l fi"><img alt="Firhanmaulanarusli" class="l fc bx abn abo cw" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1_QVq5Tm5q7ZlZZa2rF3L2qQ.jpg" width="20" height="20" loading="lazy"><div class="fq bx l abn abo fr n ax fs"></div></div></a></div></div></div><div class="abp l"><div><div class="bl" aria-hidden="false" aria-describedby="128" aria-labelledby="128"><a class="af ag ah ai aj ak al am an ao ap aq ar ja ab q" rel="noopener follow" href="https://medium.com/@firhanmaulanarusli?source=read_next_recirc-----c62f55af492d----3---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><p class="be b du z px abq pz qa abr qc abs qd bj">Firhanmaulanarusli</p></a></div></div></div></div><div class="abt abu abv abw abx aby abz aca acb acc l gm"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/@firhanmaulanarusli/ktp-ocr-in-python-using-pytesseract-f079e8facd36?source=read_next_recirc-----c62f55af492d----3---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div title=""><h2 class="be hf nw ny acd ace nz oa oc acf acg od nf ach aci acj ack nj acl acm acn aco nn acp acq acr acs px pz qa qc qd bj">KTP-OCR in Python using Pytesseract</h2></div><div class="act l"><h3 class="be b iy z px py pz qa qb qc qd dt">KTP-OCR is an open source python package that attempts to create a production grade KTP extractor. The aim of the package is to extract as…</h3></div></a></div><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/@firhanmaulanarusli/ktp-ocr-in-python-using-pytesseract-f079e8facd36?source=read_next_recirc-----c62f55af492d----3---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><span class="be b du z dt"><div class="ab q"><span>2 min read</span><span class="jb l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span>Jan 5, 2024</span></div></span></a><div class="acu acv acw acx acy l"><div class="ab co"><div class="am acz ada adb adc add ade adf adg adh adi ab q"><div class="ab q kt"><div class="pw-multi-vote-icon fi ku kv kw kx"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Ff079e8facd36&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40firhanmaulanarusli%2Fktp-ocr-in-python-using-pytesseract-f079e8facd36&amp;user=Firhanmaulanarusli&amp;userId=1094cd2a0b37&amp;source=-----f079e8facd36----3-----------------clap_footer----d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><div><div class="bl" aria-hidden="false" aria-describedby="129" aria-labelledby="129"><div class="ky ao kz la lb lc am ld le lf kx"><svg width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" clip-rule="evenodd" d="M11.37.83L12 3.28l.63-2.45h-1.26zM13.92 3.95l1.52-2.1-1.18-.4-.34 2.5zM8.59 1.84l1.52 2.11-.34-2.5-1.18.4zM18.52 18.92a4.23 4.23 0 0 1-2.62 1.33l.41-.37c2.39-2.4 2.86-4.95 1.4-7.63l-.91-1.6-.8-1.67c-.25-.56-.19-.98.21-1.29a.7.7 0 0 1 .55-.13c.28.05.54.23.72.5l2.37 4.16c.97 1.62 1.14 4.23-1.33 6.7zm-11-.44l-4.15-4.15a.83.83 0 0 1 1.17-1.17l2.16 2.16a.37.37 0 0 0 .51-.52l-2.15-2.16L3.6 11.2a.83.83 0 0 1 1.17-1.17l3.43 3.44a.36.36 0 0 0 .52 0 .36.36 0 0 0 0-.52L5.29 9.51l-.97-.97a.83.83 0 0 1 0-1.16.84.84 0 0 1 1.17 0l.97.97 3.44 3.43a.36.36 0 0 0 .51 0 .37.37 0 0 0 0-.52L6.98 7.83a.82.82 0 0 1-.18-.9.82.82 0 0 1 .76-.51c.22 0 .43.09.58.24l5.8 5.79a.37.37 0 0 0 .58-.42L13.4 9.67c-.26-.56-.2-.98.2-1.29a.7.7 0 0 1 .55-.13c.28.05.55.23.73.5l2.2 3.86c1.3 2.38.87 4.59-1.29 6.75a4.65 4.65 0 0 1-4.19 1.37 7.73 7.73 0 0 1-4.07-2.25zm3.23-12.5l2.12 2.11c-.41.5-.47 1.17-.13 1.9l.22.46-3.52-3.53a.81.81 0 0 1-.1-.36c0-.23.09-.43.24-.59a.85.85 0 0 1 1.17 0zm7.36 1.7a1.86 1.86 0 0 0-1.23-.84 1.44 1.44 0 0 0-1.12.27c-.3.24-.5.55-.58.89-.25-.25-.57-.4-.91-.47-.28-.04-.56 0-.82.1l-2.18-2.18a1.56 1.56 0 0 0-2.2 0c-.2.2-.33.44-.4.7a1.56 1.56 0 0 0-2.63.75 1.6 1.6 0 0 0-2.23-.04 1.56 1.56 0 0 0 0 2.2c-.24.1-.5.24-.72.45a1.56 1.56 0 0 0 0 2.2l.52.52a1.56 1.56 0 0 0-.75 2.61L7 19a8.46 8.46 0 0 0 4.48 2.45 5.18 5.18 0 0 0 3.36-.5 4.89 4.89 0 0 0 4.2-1.51c2.75-2.77 2.54-5.74 1.43-7.59L18.1 7.68z"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lg lh li lj lk ll lm"><div><div class="bl" aria-hidden="false" aria-describedby="181" aria-labelledby="181"><p class="be b du z dt"><button class="af ag ah ai aj ak al am an ao ap aq ar as at xr lv">3<span class="l h g f sh si"></span></button></p></div></div></div></div><div class="adj l"><div><div class="bl" aria-hidden="false" aria-describedby="130" aria-labelledby="130"><a class="af fj ah ky aj ak al lr an ao ap aq ar as at lq ab q ls lt" aria-label="responses" rel="noopener follow" href="https://medium.com/@firhanmaulanarusli/ktp-ocr-in-python-using-pytesseract-f079e8facd36?responsesOpen=true&amp;sortBy=REVERSE_CHRON&amp;source=read_next_recirc-----c62f55af492d----3---------------------d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><svg width="24" height="24" viewBox="0 0 24 24" class=""><path d="M18 16.8a7.14 7.14 0 0 0 2.24-5.32c0-4.12-3.53-7.48-8.05-7.48C7.67 4 4 7.36 4 11.48c0 4.13 3.67 7.48 8.2 7.48a8.9 8.9 0 0 0 2.38-.32c.23.2.48.39.75.56 1.06.69 2.2 1.04 3.4 1.04.22 0 .4-.11.48-.29a.5.5 0 0 0-.04-.52 6.4 6.4 0 0 1-1.16-2.65v.02zm-3.12 1.06l-.06-.22-.32.1a8 8 0 0 1-2.3.33c-4.03 0-7.3-2.96-7.3-6.59S8.17 4.9 12.2 4.9c4 0 7.1 2.96 7.1 6.6 0 1.8-.6 3.47-2.02 4.72l-.2.16v.26l.02.3a6.74 6.74 0 0 0 .88 2.4 5.27 5.27 0 0 1-2.17-.86c-.28-.17-.72-.38-.94-.59l.01-.02z"></path></svg><p class="be b du z dt"><span class="pw-responses-count lo lp">1</span></p></a></div></div></div></div><div class="ab q adk adl"><div class=""><div><div class="bl" aria-hidden="false" aria-describedby="131" aria-labelledby="131"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Ff079e8facd36&amp;operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2F%40firhanmaulanarusli%2Fktp-ocr-in-python-using-pytesseract-f079e8facd36&amp;source=-----c62f55af492d----3-----------------bookmark_preview----d24ffc16_5ec5_44c9_b003_518a8df471dc-------"><svg width="25" height="25" viewBox="0 0 25 25" fill="none" class="dt lv" aria-label="Add to list bookmark button"><path d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18V2.5zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .8.4l5.7-4.4 5.7 4.4a.5.5 0 0 0 .8-.4v-8.5a.5.5 0 0 0-1 0v7.48l-5.2-4a.5.5 0 0 0-.6 0l-5.2 4V7z" fill="currentColor"></path></svg></a></span></div></div></div></div></div></div></div></div></div></div></div></article></div></div></div><div class="tl bg tm dj dk adm adn ado"></div><a class="be b bf z bj rm ads adt adu lv ls wr eu ev ew adv adw adx ez wc wd ady adz aea fa fb fc bl fd fe" rel="noopener follow" href="https://medium.com/?source=post_page-----c62f55af492d--------------------------------"><div class="l fe">See more recommendations</div></a></div></div></div><div class="h k j"><div class="tl bg tm tn"></div><div class="ab ca"><div class="ch bg fy fz ga gb"><div class="to ab kt jk"><div class="tp tq l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://help.medium.com/hc/en-us?source=post_page-----c62f55af492d--------------------------------" rel="noopener follow"><p class="be b du z dt">Help</p></a></div><div class="tp tq l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.statuspage.io/?source=post_page-----c62f55af492d--------------------------------" rel="noopener follow"><p class="be b du z dt">Status</p></a></div><div class="tp tq l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/about?autoplay=1&amp;source=post_page-----c62f55af492d--------------------------------"><p class="be b du z dt">About</p></a></div><div class="tp tq l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----c62f55af492d--------------------------------"><p class="be b du z dt">Careers</p></a></div><div class="tp tq l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://blog.medium.com/?source=post_page-----c62f55af492d--------------------------------" rel="noopener follow"><p class="be b du z dt">Blog</p></a></div><div class="tp tq l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----c62f55af492d--------------------------------" rel="noopener follow"><p class="be b du z dt">Privacy</p></a></div><div class="tp tq l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----c62f55af492d--------------------------------" rel="noopener follow"><p class="be b du z dt">Terms</p></a></div><div class="tp tq l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://speechify.com/medium?source=post_page-----c62f55af492d--------------------------------" rel="noopener follow"><p class="be b du z dt">Text to speech</p></a></div><div class="tp l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" rel="noopener follow" href="https://medium.com/business?source=post_page-----c62f55af492d--------------------------------"><p class="be b du z dt">Teams</p></a></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20240315-153240-a3ec866aac"</script><script>window.__GRAPHQL_URI__ = "https://medium.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"cache":{"experimentGroupSet":true,"reason":"","group":"enabled","tags":["group-edgeCachePosts","post-c62f55af492d","user-7e94df6b7255"],"serverVariantState":"44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a","middlewareEnabled":true,"cacheStatus":"DYNAMIC","shouldUseCache":true,"vary":[],"loHomepageEnabled":false,"updatedPostPreviewsEnabled":false,"customMocPreviewWeightThreshold":"control"},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"isFirefox":false,"routingEntity":{"type":"DEFAULT","explicit":false},"viewerIsBot":false},"debug":{"requestId":"883fa6d0-4d17-4c5b-946e-168e83e5c7d5","hybridDevServices":[],"originalSpanCarrier":{"ot-tracer-spanid":"6e8d32475b666c8e","ot-tracer-traceid":"3b98d5a67277bc6c","ot-tracer-sampled":"true"}},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Fmedium.com\u002F@baptisteloquette.entr\u002Flangchain-arxiv-tutor-data-loading-c62f55af492d","host":"medium.com","hostname":"medium.com","referrer":"","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false,"queryString":"","currentHash":""},"config":{"nodeEnv":"production","version":"main-20240315-153240-a3ec866aac","target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","recaptchaEnterpriseKeyId":"6Le-uGgpAAAAAPprRaokM8AKthQ9KNGdoxaGUvVp","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20240315-153240-a3ec866aac","commit":"a3ec866aacdcd1306dcb3d8255d951254f7392c8"}},"datacenter":"us"},"googleAnalyticsCode":"G-7JY7T788PK","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumMastodonDomainName":"me.dm","mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*kFrc4tBFM_tCis-2Ic87WA.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"ds2nn34bg2z7j5gd","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyWithTrial":"d5ee3dbe3db8","monthlyPremium":"fa741a9b47a2","yearly":"a40ad4a43185","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7","yearlyPremium":"e21bd2c12166","monthlyCad":"p52orjkaceei","yearlyCad":"h4q9g2up9ktt"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06","fiftyPercentOffOneYear":"FIFTY_PERCENT_OFF_ONE_YEAR"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd","q8qw":"usd","d9y6":"usd","fx7w":"cad","nwf2":"cad"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"},"imageUploadMaxSizeMb":25,"staffPicks":{"title":"Staff Picks","catalogId":"c7bc6e1ee00f"}},"session":{"xsrf":""}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","isLoggedIn":false,"viewer":null,"collectionByDomainOrSlug({\"domainOrSlug\":\"medium.com\"})":null,"postResult({\"id\":\"c62f55af492d\"})":{"__ref":"Post:c62f55af492d"}},"LinkedAccounts:7e94df6b7255":{"__typename":"LinkedAccounts","mastodon":null,"id":"7e94df6b7255"},"UserViewerEdge:userId:7e94df6b7255-viewerId:lo_a2375f4e1a4b":{"__typename":"UserViewerEdge","id":"userId:7e94df6b7255-viewerId:lo_a2375f4e1a4b","isFollowing":false,"isUser":false,"isMuting":false},"NewsletterV3:16c558504712":{"__typename":"NewsletterV3","id":"16c558504712","type":"NEWSLETTER_TYPE_AUTHOR","slug":"7e94df6b7255","name":"7e94df6b7255","collection":null,"user":{"__ref":"User:7e94df6b7255"}},"User:7e94df6b7255":{"__typename":"User","id":"7e94df6b7255","name":"Baptiste L.","username":"baptisteloquette.entr","newsletterV3":{"__ref":"NewsletterV3:16c558504712"},"linkedAccounts":{"__ref":"LinkedAccounts:7e94df6b7255"},"isSuspended":false,"imageId":"1*jiwQ9IOKR15F1zwNKrN_Ow.png","mediumMemberAt":1701038638000,"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"socialStats":{"__typename":"SocialStats","followerCount":81},"customDomainState":null,"hasSubdomain":false,"bio":"Passionated about Semantic Search, NLP, Deep Learning & Graphs | 21","isPartnerProgramEnrolled":true,"viewerEdge":{"__ref":"UserViewerEdge:userId:7e94df6b7255-viewerId:lo_a2375f4e1a4b"},"viewerIsUser":false,"postSubscribeMembershipUpsellShownAt":0,"allowNotes":true,"membership":{"__ref":"Membership:3b79d0a5c101"},"twitterScreenName":""},"ImageMetadata:1*UpAKNhJYTpaQ4eWJKzWeDQ.png":{"__typename":"ImageMetadata","id":"1*UpAKNhJYTpaQ4eWJKzWeDQ.png","originalHeight":512,"originalWidth":512,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:bc222b2b2494_0":{"__typename":"Paragraph","id":"bc222b2b2494_0","name":"3469","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*UpAKNhJYTpaQ4eWJKzWeDQ.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_1":{"__typename":"Paragraph","id":"bc222b2b2494_1","name":"d5a3","type":"H3","href":null,"layout":null,"metadata":null,"text":"Data Loading, OCR and Chunking – LangChain Arxiv Tutor","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_2":{"__typename":"Paragraph","id":"bc222b2b2494_2","name":"7eda","type":"P","href":null,"layout":null,"metadata":null,"text":"This Series of Articles covers the usage of LangChain, to create an Arxiv Tutor. That will allow anyone to interact in different ways with the papers to enhance engagement, generate tests, …","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_3":{"__typename":"Paragraph","id":"bc222b2b2494_3","name":"31b7","type":"P","href":null,"layout":null,"metadata":null,"text":"Here we will discuss Data Loading, OCR and Vector Databases storage","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_4":{"__typename":"Paragraph","id":"bc222b2b2494_4","name":"8c8e","type":"P","href":null,"layout":null,"metadata":null,"text":"In this series of articles we will explore through the Arxiv Tutor the following paper :","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_5":{"__typename":"Paragraph","id":"bc222b2b2494_5","name":"7263","type":"P","href":null,"layout":null,"metadata":null,"text":"Unifying Large Language Models and Knowledge Graphs: A Roadmap","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":62,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":0,"end":62,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_6":{"__typename":"Paragraph","id":"bc222b2b2494_6","name":"0186","type":"P","href":null,"layout":null,"metadata":null,"text":"Shirui Pan, Senior Member, IEEE, Linhao Luo,\nYufei Wang, Chen Chen, Jiapu Wang, Xindong W","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":0,"end":89,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_7":{"__typename":"Paragraph","id":"bc222b2b2494_7","name":"d972","type":"P","href":null,"layout":null,"metadata":null,"text":"I selected a relatively long paper (28 pages), because for long documents you might want to considers some problems with the usage of LLMs","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_8":{"__typename":"Paragraph","id":"bc222b2b2494_8","name":"e645","type":"H3","href":null,"layout":null,"metadata":null,"text":"Download Papers","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_9":{"__typename":"Paragraph","id":"bc222b2b2494_9","name":"b07e","type":"P","href":null,"layout":null,"metadata":null,"text":"First download the paper","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_10":{"__typename":"Paragraph","id":"bc222b2b2494_10","name":"289d","type":"PRE","href":null,"layout":null,"metadata":null,"text":"import requests\nimport os\n\ndef download_pdf_paper_from_url(url):\n    paper_number    =   os.path.basename(url).strip(\".pdf\")\n    res             =   requests.get(url)\n    pdf_path        =   f\"papers\u002F{paper_number}.pdf\"\n    with open(pdf_path, 'wb') as f:\n        f.write(res.content)\n    return paper_number\n\nlink            =   \"https:\u002F\u002Farxiv.org\u002Fpdf\u002F2306.08302.pdf\"\npaper_number    =   download_pdf_paper_from_url(link)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_11":{"__typename":"Paragraph","id":"bc222b2b2494_11","name":"8d22","type":"P","href":null,"layout":null,"metadata":null,"text":"We load the paper using LangChain’s PDFMinerLoader (There are different PDF Loaders, but PDFMiner (based on pdfminer.six) is my go-to especially for scientific litterature)","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":36,"end":50,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_12":{"__typename":"Paragraph","id":"bc222b2b2494_12","name":"72a0","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from langchain.document_loaders import PDFMinerLoader\ndocs    =   PDFMinerLoader(f\"papers\u002F{paper_number}.pdf\").load()","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_13":{"__typename":"Paragraph","id":"bc222b2b2494_13","name":"ea7d","type":"H3","href":null,"layout":null,"metadata":null,"text":"Chunking with LangChain","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_14":{"__typename":"Paragraph","id":"bc222b2b2494_14","name":"e032","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s chunk the content of the paper.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_15":{"__typename":"Paragraph","id":"bc222b2b2494_15","name":"6b66","type":"P","href":null,"layout":null,"metadata":null,"text":"We chunk the paper in order to have context lengths that do not hit the LLM’s tokens limitation, while trying to preserve semantics across the chunks.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_16":{"__typename":"Paragraph","id":"bc222b2b2494_16","name":"7616","type":"P","href":null,"layout":null,"metadata":null,"text":"LangChain offer RecursiveCharacterTextSplitter that tries to preserve semantics by keeping the paragraphs together. Simply because paragraphs are generally grouped for a semantic reason.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":16,"end":46,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_17":{"__typename":"Paragraph","id":"bc222b2b2494_17","name":"5e11","type":"P","href":null,"layout":null,"metadata":null,"text":"It does so by first trying to split with “\\n\\n” then “\\n”, “ “, and finally “”.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_18":{"__typename":"Paragraph","id":"bc222b2b2494_18","name":"d92a","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from langchain.text_splitter import RecursiveCharacterTextSplitter\n\ntext_splitter   =   RecursiveCharacterTextSplitter(\n    chunk_size=700, # Specify the character chunk size\n    chunk_overlap=0, # \"Allowed\" Overlap across chunks\n    length_function=len # Function used to evaluate the chunk size (here in terms of characters)\n)\n\ndocs    =   text_splitter.split_documents(docs)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_19":{"__typename":"Paragraph","id":"bc222b2b2494_19","name":"80c3","type":"P","href":null,"layout":null,"metadata":null,"text":"This is what we get :","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_20":{"__typename":"Paragraph","id":"bc222b2b2494_20","name":"1d08","type":"PRE","href":null,"layout":null,"metadata":null,"text":"[Document(page_content='3\\n2\\n0\\n2\\n\\nn\\nu\\nJ\\n\\n0\\n2\\n\\n]\\nL\\nC\\n.\\ns\\nc\\n[\\n\\n2\\nv\\n2\\n0\\n3\\n8\\n0\\n.\\n6\\n0\\n3\\n2\\n:\\nv\\ni\\nX\\nr\\na\\n\\nJOURNAL OF LATEX CLASS FILES, VOL. 14, NO. 8, AUGUST 2021\\n\\n1\\n\\nUnifying Large Language Models and\\nKnowledge Graphs: A Roadmap\\n\\nShirui Pan, Senior Member, IEEE, Linhao Luo,\\nYufei Wang, Chen Chen, Jiapu Wang, Xindong Wu, Fellow, IEEE', metadata={'source': 'papers\u002F2306.08302.pdf'}),\n Document(page_content='Abstract—Large language models (LLMs), such as ChatGPT and GPT4, are making new waves in the field of natural language\\nprocessing and artificial intelligence, due to their emergent ability and generalizability. However, LLMs are black-box models, which\\noften fall short of capturing and accessing factual knowledge. In contrast, Knowledge Graphs (KGs), Wikipedia and Huapu for example,\\nare structured knowledge models that explicitly store rich factual knowledge. KGs can enhance LLMs by providing external knowledge\\nfor inference and interpretability. Meanwhile, KGs are difficult to construct and evolving by nature, which challenges the existing', metadata={'source': 'papers\u002F2306.08302.pdf'}),\n Document(page_content='methods in KGs to generate new facts and represent unseen knowledge. Therefore, it is complementary to unify LLMs and KGs\\ntogether and simultaneously leverage their advantages. In this article, we present a forward-looking roadmap for the unification of LLMs\\nand KGs. Our roadmap consists of three general frameworks, namely, 1) KG-enhanced LLMs, which incorporate KGs during the\\npre-training and inference phases of LLMs, or for the purpose of enhancing understanding of the knowledge learned by LLMs; 2)\\nLLM-augmented KGs, that leverage LLMs for different KG tasks such as embedding, completion, construction, graph-to-text', metadata={'source': 'papers\u002F2306.08302.pdf'}),\n...,\n Document(page_content='[256] T. Sun, Y. Shao, H. Qian, X. Huang, and X. Qiu, “Black-box tuning\\nfor language-model-as-a-service,” in International Conference on\\nMachine Learning. PMLR, 2022, pp. 20 841–20 855.\\n\\n[257] X. Chen, A. Shrivastava, and A. Gupta, “NEIL: extracting visual\\nknowledge from web data,” in IEEE International Conference on\\nComputer Vision, ICCV 2013, Sydney, Australia, December 1-8, 2013.\\nIEEE Computer Society, 2013, pp. 1409–1416. [Online]. Available:\\nhttps:\u002F\u002Fdoi.org\u002F10.1109\u002FICCV.2013.178', metadata={'source': 'papers\u002F2306.08302.pdf'}),\n Document(page_content='[Online]. Available: https:\u002F\u002Fceur-ws.org\u002FVol-2276\u002Fpaper5.pdf', metadata={'source': 'papers\u002F2306.08302.pdf'}),\n Document(page_content='[259] Z. Chen, Y. Huang, J. Chen, Y. Geng, Y. Fang, J. Z. Pan, N. Zhang,\\nand W. Zhang, “Lako: Knowledge-driven visual estion answer-\\ning via late knowledge-to-text injection,” 2022.\\n\\n[260] R. Girdhar, A. El-Nouby, Z. Liu, M. Singh, K. V. Alwala, A. Joulin,\\nand I. Misra, “Imagebind: One embedding space to bind them\\nall,” in Proceedings of the IEEE\u002FCVF Conference on Computer Vision\\nand Pattern Recognition, 2023, pp. 15 180–15 190.\\n\\n[261] J. Zhang, Z. Yin, P. Chen, and S. Nichele, “Emotion recognition\\nusing multi-modal data and machine learning techniques: A\\ntutorial and review,” Information Fusion, vol. 59, pp. 103–126,\\n2020.', metadata={'source': 'papers\u002F2306.08302.pdf'}),\n Document(page_content='[262] Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and S. Y. Philip,\\n“A comprehensive survey on graph neural networks,” IEEE\\ntransactions on neural networks and learning systems, vol. 32, no. 1,\\npp. 4–24, 2020.\\n\\n[263] T. Wu, M. Caccia, Z. Li, Y.-F. Li, G. Qi, and G. Haffari, “Pretrained\\nlanguage model in continual learning: A comparative study,” in\\nInternational Conference on Learning Representations, 2022.', metadata={'source': 'papers\u002F2306.08302.pdf'})]]","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"vbnet"},"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_21":{"__typename":"Paragraph","id":"bc222b2b2494_21","name":"c272","type":"P","href":null,"layout":null,"metadata":null,"text":"We can see that the results are good. But I want to handle the titles and exclude the references (as for interactions or any of our use cases, this is not valuable pieces of information)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_22":{"__typename":"Paragraph","id":"bc222b2b2494_22","name":"9bc2","type":"P","href":null,"layout":null,"metadata":null,"text":"To handle both, I propose OCR based parsing method.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_23":{"__typename":"Paragraph","id":"bc222b2b2494_23","name":"bf6c","type":"H3","href":null,"layout":null,"metadata":null,"text":"Layout Parsing with LayoutParser","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_24":{"__typename":"Paragraph","id":"bc222b2b2494_24","name":"071a","type":"P","href":null,"layout":null,"metadata":null,"text":"layoutparser is a great library that offers different Computer Vision Models to perform layout analysis on Documents.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":0,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_25":{"__typename":"Paragraph","id":"bc222b2b2494_25","name":"5417","type":"P","href":null,"layout":null,"metadata":null,"text":"Note that these model will detect paragraphs, ultimately respecting the assumption that paragraphs are the most semantic piece of information.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_26":{"__typename":"Paragraph","id":"bc222b2b2494_26","name":"d15a","type":"MIXTAPE_EMBED","href":null,"layout":null,"metadata":null,"text":"GitHub - Layout-Parser\u002Flayout-parser: A Unified Toolkit for Deep Learning Based Document Image…\nA Unified Toolkit for Deep Learning Based Document Image Analysis - GitHub - Layout-Parser\u002Flayout-parser: A Unified…github.com","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":222,"href":"https:\u002F\u002Fgithub.com\u002FLayout-Parser\u002Flayout-parser","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":95,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":96,"end":212,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":{"__typename":"MixtapeMetadata","href":"https:\u002F\u002Fgithub.com\u002FLayout-Parser\u002Flayout-parser","mediaResource":{"__typename":"MediaResource","mediumCatalog":null},"thumbnailImageId":"0*tALmt-8ZHIEZSzqL"}},"Paragraph:bc222b2b2494_27":{"__typename":"Paragraph","id":"bc222b2b2494_27","name":"3864","type":"P","href":null,"layout":null,"metadata":null,"text":"We will use PubLayNet’s mask_rcnn_X_101_32x8d_FPN_3x , that model is purposed to perform layout parsing of scientific papers.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":24,"end":52,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_28":{"__typename":"Paragraph","id":"bc222b2b2494_28","name":"79bc","type":"P","href":null,"layout":null,"metadata":null,"text":"A Mask-RCNN comport 3 main components :","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_29":{"__typename":"Paragraph","id":"bc222b2b2494_29","name":"dc70","type":"P","href":null,"layout":null,"metadata":null,"text":"First a convolutional NN to extract feature maps. Second a RPN (Region Proposal Network) that will make use of the feature maps to propose and refine a certain number of regions of interests. The Third component will gather the best propositions, then refine them further, to produce a segmentation mask.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":5,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":50,"end":56,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":196,"end":201,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":64,"end":87,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_30":{"__typename":"Paragraph","id":"bc222b2b2494_30","name":"4ba9","type":"OLI","href":null,"layout":null,"metadata":null,"text":"First we convert the PDF’s into images using pdf2image","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":45,"end":54,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":54,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_31":{"__typename":"Paragraph","id":"bc222b2b2494_31","name":"54e1","type":"PRE","href":null,"layout":null,"metadata":null,"text":"import os\nfrom pdf2image import convert_from_path\n\ndef convert_pdf_to_images(pdf_path):\n    img_path    =   os.path.join(\"papers_images\", os.path.basename(pdf_path).strip(\".pdf\") + \"_images\")\n    if not os.path.exists(img_path):\n        os.makedirs(img_path)\n    images      =   convert_from_path(pdf_path=pdf_path)\n    for i in range(len(images)):\n        images[i].save(os.path.join(img_path, \"page\" + str(i) + \".jpg\"), \"JPEG\")\n    print(\"Images Saved !\")\n    return img_path\n\nimgs_path   =   convert_pdf_to_images(f\"papers\u002F{paper_number}.pdf\")","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_32":{"__typename":"Paragraph","id":"bc222b2b2494_32","name":"c725","type":"P","href":null,"layout":null,"metadata":null,"text":"2. Load the model","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":3,"end":17,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_33":{"__typename":"Paragraph","id":"bc222b2b2494_33","name":"c5ec","type":"PRE","href":null,"layout":null,"metadata":null,"text":"import layoutparser as lp\n\nmodel_publay    =   lp.Detectron2LayoutModel('lp:\u002F\u002FPubLayNet\u002Fmask_rcnn_X_101_32x8d_FPN_3x\u002Fconfig',\n                    extra_config=[\"MODEL.ROI_HEADS.SCORE_THRESH_TEST\", 0.6],\n                    label_map={0: \"Text\", 1: \"Title\", 2: \"List\", 3:\"Table\", 4:\"Figure\"})","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_34":{"__typename":"Paragraph","id":"bc222b2b2494_34","name":"3553","type":"P","href":null,"layout":null,"metadata":null,"text":"As you can see we need to specify a “confidence” threshold. Then we just specify the mapping of the labels for convenience.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"EM","start":37,"end":47,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":48,"end":49,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_35":{"__typename":"Paragraph","id":"bc222b2b2494_35","name":"3603","type":"P","href":null,"layout":null,"metadata":null,"text":"Let’s see the model in action","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_36":{"__typename":"Paragraph","id":"bc222b2b2494_36","name":"f59f","type":"PRE","href":null,"layout":null,"metadata":null,"text":"import cv2\nimport os\n\npage_idx    =   6\nimg_path    =   os.path.join(pdf_path, f\"page{page_idx}.jpg\")\nimg         =   cv2.imread(img_path)\nimg         =   img[..., ::-1]","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_37":{"__typename":"Paragraph","id":"bc222b2b2494_37","name":"aba3","type":"PRE","href":null,"layout":null,"metadata":null,"text":"layout  =   model_publay.detect(img)\nlp.draw_box(img, layout)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*L_qB_D0tu3xQqftuIZcPGw.png":{"__typename":"ImageMetadata","id":"1*L_qB_D0tu3xQqftuIZcPGw.png","originalHeight":2200,"originalWidth":1700,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:bc222b2b2494_38":{"__typename":"Paragraph","id":"bc222b2b2494_38","name":"6715","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*L_qB_D0tu3xQqftuIZcPGw.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_39":{"__typename":"Paragraph","id":"bc222b2b2494_39","name":"d423","type":"P","href":null,"layout":null,"metadata":null,"text":"As we can see it detects Figures, Titles and Texts, it also can detect Lists. While this can be seen as non-necessary, it will really be useful in the next articles.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_40":{"__typename":"Paragraph","id":"bc222b2b2494_40","name":"5931","type":"P","href":null,"layout":null,"metadata":null,"text":"As this article is not about OCR, I will only explain briefly the following piece of code :","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_41":{"__typename":"Paragraph","id":"bc222b2b2494_41","name":"7651","type":"PRE","href":null,"layout":null,"metadata":null,"text":"def get_coordinate(data):\n\n  x1 = data.block.x_1\n  y1 = data.block.y_1\n  x2 = data.block.x_2\n  y2 = data.block.y_2\n\n  return torch.tensor([[x1, y1, x2, y2]], dtype=torch.float)\n\ndef get_iou(box_1, box_2):\n\n  return bops.box_iou(box_1, box_2)\n\ndef get_area(bbox):\n  w = bbox[0, 2] - bbox[0, 0] # Width\n  h = bbox[0, 3] - bbox[0, 1] # Height\n  area  = w * h\n\n  return area\n\ndef refine_bboxes(block_1, block_2):\n\n  bb1 = set_coordinate(block_1)\n  bb2 = set_coordinate(block_2)\n\n  iou = get_iou(bb1, bb2)\n\n  if iou.tolist()[0][0] != 0.0:\n\n    a1 = get_area(bb1)\n    a2 = get_area(bb2)\n\n    block_2.set(type='None', inplace= True) if a1 \u003E a2 else block_1.set(type='None', inplace= True)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_42":{"__typename":"Paragraph","id":"bc222b2b2494_42","name":"4522","type":"P","href":null,"layout":null,"metadata":null,"text":"Here handle bboxes overlaps by computing the IntersectionOverUnion of each detected bboxes. If IoU \u003E 0 then we have an overlap, we thus compute the area of the 2 overlapping bboxes, and only keep the bbox with the greatest area, by setting it’s type to \"None\" .","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":245,"end":249,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":253,"end":259,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_43":{"__typename":"Paragraph","id":"bc222b2b2494_43","name":"6781","type":"PRE","href":null,"layout":null,"metadata":null,"text":"ocr_agent                   =   lp.TesseractAgent(languages=\"eng\")\n\ndef extract_text_pdf_image_PubLay_OCR(img_path):\n    texts       =   []\n    image       =   cv2.imread(img_path)\n    image       =   image[..., ::-1]\n    layout      =   model_publay.detect(image)\n    text_blocks =   lp.Layout([b for b in layout if b.type in ['Text', 'List', 'Title']])\n\n    # Organize text blocks based on their positions on the page\n    h, w            =   image.shape[:2]\n    left_interval   =   lp.Interval(0, w\u002F2*1.05, axis='x').put_on_canvas(image)\n    left_blocks     =   text_blocks.filter_by(left_interval, center=True)\n    left_blocks.sort(key = lambda b:b.coordinates[1], inplace=True)\n\n    right_blocks            =   lp.Layout([b for b in text_blocks if b not in left_blocks])\n    right_blocks.sort(key   =   lambda b:b.coordinates[1], inplace=True)\n\n    text_blocks = lp.Layout([b.set(id = idx) for idx, b in enumerate(left_blocks + right_blocks)])\n\n    for layout_i in text_blocks:    # If some of the blocks overlap -\u003E Take the one with the most associated area\n        for layout_j in text_blocks:\n            if layout_i != layout_j:\n                refine_blocks(layout_i, layout_j)\n\n    for block in text_blocks:\n        segment_image = (block\n                        .pad(left=5, right=5, top=5, bottom=5)\n                        .crop_image(image))\n            # add padding in each image segment can help\n            # improve robustness \n            \n        text = ocr_agent.detect(segment_image)\n        block.set(text=text, inplace=True)\n    for l in text_blocks:\n        texts.append([l.text, l.type])\n    return texts","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_44":{"__typename":"Paragraph","id":"bc222b2b2494_44","name":"3b35","type":"P","href":null,"layout":null,"metadata":null,"text":"Here we :","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_45":{"__typename":"Paragraph","id":"bc222b2b2494_45","name":"d9f8","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Initialize the ocr_agent that will extract the text from the detected boxes, using Tesseract. Note that you can specify multiple languages with the following format : languages=[\"eng\", \"fra\"] .","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":15,"end":24,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"CODE","start":167,"end":191,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_46":{"__typename":"Paragraph","id":"bc222b2b2494_46","name":"7331","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Pass the image through the model. Only keeping the bboxes detected with labels “Text”, “Title”, or “List”. Ultimately excluding Figures.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_47":{"__typename":"Paragraph","id":"bc222b2b2494_47","name":"7ee5","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Sort the boxes by their positions on the page. Note that paper’s pages can be in 2 columns, we thus sort from top to bottom, then left to right","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_48":{"__typename":"Paragraph","id":"bc222b2b2494_48","name":"f6db","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Apply the refine_blocks function to handle bboxe’s overlap","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":10,"end":23,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_49":{"__typename":"Paragraph","id":"bc222b2b2494_49","name":"5771","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Infer the text for each bboxes, here we pad each images by 5. Padding improve the ocr_agent‘s accuracy.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":82,"end":91,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_50":{"__typename":"Paragraph","id":"bc222b2b2494_50","name":"8011","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Append to a list the texts and the labels.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_51":{"__typename":"Paragraph","id":"bc222b2b2494_51","name":"db36","type":"PRE","href":null,"layout":null,"metadata":null,"text":"def images_2_OCR(imgs_paths):\n    docs        =   []\n    for img_path_idx in range(len(os.listdir(imgs_paths))):\n        img_path        =   os.path.join(imgs_paths, \"page{}.jpg\".format(img_path_idx))\n        page_content    =   extract_text_pdf_image_PubLay_OCR(img_path)\n        for content in page_content:\n            text    =   content[0]\n            cat     =   content[1]\n            if \"REFERENCES\" in text and cat == \"Title\":\n                return docs\n            metadata        =   {\"page_number\" : img_path_idx, \"category\" : cat, \"source\" : paper_number}\n            docs.append(Document(page_content=text, metadata=metadata))\n\n    return docs","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_52":{"__typename":"Paragraph","id":"bc222b2b2494_52","name":"efb3","type":"P","href":null,"layout":null,"metadata":null,"text":"In this function, for each image we detect the text. Then create a list of LangChain Documents with metadatas.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_53":{"__typename":"Paragraph","id":"bc222b2b2494_53","name":"99ab","type":"P","href":null,"layout":null,"metadata":null,"text":"Note that we exclude all the References with :","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_54":{"__typename":"Paragraph","id":"bc222b2b2494_54","name":"7d2b","type":"PRE","href":null,"layout":null,"metadata":null,"text":"if \"REFERENCES\" in text and cat == \"Title\":\n  return docs","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_55":{"__typename":"Paragraph","id":"bc222b2b2494_55","name":"d7ef","type":"H3","href":null,"layout":null,"metadata":null,"text":"Add the referenced papers","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_56":{"__typename":"Paragraph","id":"bc222b2b2494_56","name":"cb65","type":"P","href":null,"layout":null,"metadata":null,"text":"While the text referencing the papers, is not valuable for tasks like RetrievalQA, and especially Summarization. We can make use of the referenced papers to get “Out-of-scope” contexts.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_57":{"__typename":"Paragraph","id":"bc222b2b2494_57","name":"3f99","type":"P","href":null,"layout":null,"metadata":null,"text":"First we gather the referenced Arxiv paper’s number through the mentionned URLs :","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_58":{"__typename":"Paragraph","id":"bc222b2b2494_58","name":"4e3a","type":"PRE","href":null,"layout":null,"metadata":null,"text":"adjacents_papers_urls       =   []\nadjacents_papers_numbers    =   []\nfor doc in docs:\n    adjacents_papers_urls.extend([re.sub(\"abs\", \"pdf\", url) + \".pdf\" for url in re.findall(r'(https?:\u002F\u002Farxiv.org\u002Fabs\\S+)', doc.page_content)])\n    adjacents_papers_numbers.extend([re.findall('\\d{4}\\.\\d{5}', url)[0] for url in re.findall(r'(https?:\u002F\u002Farxiv.org\u002Fabs\\S+)', doc.page_content)])","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"AUTO","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_59":{"__typename":"Paragraph","id":"bc222b2b2494_59","name":"9a14","type":"P","href":null,"layout":null,"metadata":null,"text":"Then iterate over those retrieved numbers and chunk :","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_60":{"__typename":"Paragraph","id":"bc222b2b2494_60","name":"66de","type":"PRE","href":null,"layout":null,"metadata":null,"text":"from langchain.document_loaders import ArxivLoader\nfor pdf_number in adjacents_papers_numbers:\n    adj_docs    =   ArxivLoader(query=pdf_number)\n    adj_docs    =   PDFMinerLoader(f\"papers\u002F{pdf_number}.pdf\").load()\n    adj_docs    =   text_splitter.split_documents(docs)\n    vdb_chunks.add_documents(docs)","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":{"__typename":"CodeBlockMetadata","mode":"EXPLICIT","lang":"python"},"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_61":{"__typename":"Paragraph","id":"bc222b2b2494_61","name":"3103","type":"P","href":null,"layout":null,"metadata":null,"text":"Of course you can do this recursively for every mentioned papers.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_62":{"__typename":"Paragraph","id":"bc222b2b2494_62","name":"b7d1","type":"P","href":null,"layout":null,"metadata":null,"text":"In the next article we will populate a Vector Database and begin coding the interaction part.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_63":{"__typename":"Paragraph","id":"bc222b2b2494_63","name":"993f","type":"H3","href":null,"layout":null,"metadata":null,"text":"Few Notes :","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_64":{"__typename":"Paragraph","id":"bc222b2b2494_64","name":"d8ba","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Performing OCR for layout parsing is a good idea, but you must consider that it takes more computing.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_65":{"__typename":"Paragraph","id":"bc222b2b2494_65","name":"fed8","type":"ULI","href":null,"layout":null,"metadata":null,"text":"Deploying such models will be costlier than using LangChain’s Loader or any deterministic chunking methods.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:bc222b2b2494_66":{"__typename":"Paragraph","id":"bc222b2b2494_66","name":"f472","type":"ULI","href":null,"layout":null,"metadata":null,"text":"As the “layout-parsing” model is trained on mostly specific format (here scientific litterature), it can not generalize well on other documents, especially with one’s full of colors. The layoutparser library offers other models for different types of Documents, that you can explore.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"CODE","start":187,"end":199,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Membership:3b79d0a5c101":{"__typename":"Membership","tier":"MEMBER","id":"3b79d0a5c101"},"Tag:llm":{"__typename":"Tag","id":"llm","displayTitle":"Llm","normalizedTagSlug":"llm"},"Tag:chatgpt":{"__typename":"Tag","id":"chatgpt","displayTitle":"ChatGPT","normalizedTagSlug":"chatgpt"},"Tag:gpt":{"__typename":"Tag","id":"gpt","displayTitle":"Gpt","normalizedTagSlug":"gpt"},"Tag:deep-learning":{"__typename":"Tag","id":"deep-learning","displayTitle":"Deep Learning","normalizedTagSlug":"deep-learning"},"Tag:nlp":{"__typename":"Tag","id":"nlp","displayTitle":"NLP","normalizedTagSlug":"nlp"},"Post:c62f55af492d":{"__typename":"Post","id":"c62f55af492d","collection":null,"content({\"postMeteringOptions\":{}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"bodyModel":{"__typename":"RichText","sections":[{"__typename":"Section","name":"d4d2","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null},{"__typename":"Section","name":"4e39","startIndex":62,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}],"paragraphs":[{"__ref":"Paragraph:bc222b2b2494_0"},{"__ref":"Paragraph:bc222b2b2494_1"},{"__ref":"Paragraph:bc222b2b2494_2"},{"__ref":"Paragraph:bc222b2b2494_3"},{"__ref":"Paragraph:bc222b2b2494_4"},{"__ref":"Paragraph:bc222b2b2494_5"},{"__ref":"Paragraph:bc222b2b2494_6"},{"__ref":"Paragraph:bc222b2b2494_7"},{"__ref":"Paragraph:bc222b2b2494_8"},{"__ref":"Paragraph:bc222b2b2494_9"},{"__ref":"Paragraph:bc222b2b2494_10"},{"__ref":"Paragraph:bc222b2b2494_11"},{"__ref":"Paragraph:bc222b2b2494_12"},{"__ref":"Paragraph:bc222b2b2494_13"},{"__ref":"Paragraph:bc222b2b2494_14"},{"__ref":"Paragraph:bc222b2b2494_15"},{"__ref":"Paragraph:bc222b2b2494_16"},{"__ref":"Paragraph:bc222b2b2494_17"},{"__ref":"Paragraph:bc222b2b2494_18"},{"__ref":"Paragraph:bc222b2b2494_19"},{"__ref":"Paragraph:bc222b2b2494_20"},{"__ref":"Paragraph:bc222b2b2494_21"},{"__ref":"Paragraph:bc222b2b2494_22"},{"__ref":"Paragraph:bc222b2b2494_23"},{"__ref":"Paragraph:bc222b2b2494_24"},{"__ref":"Paragraph:bc222b2b2494_25"},{"__ref":"Paragraph:bc222b2b2494_26"},{"__ref":"Paragraph:bc222b2b2494_27"},{"__ref":"Paragraph:bc222b2b2494_28"},{"__ref":"Paragraph:bc222b2b2494_29"},{"__ref":"Paragraph:bc222b2b2494_30"},{"__ref":"Paragraph:bc222b2b2494_31"},{"__ref":"Paragraph:bc222b2b2494_32"},{"__ref":"Paragraph:bc222b2b2494_33"},{"__ref":"Paragraph:bc222b2b2494_34"},{"__ref":"Paragraph:bc222b2b2494_35"},{"__ref":"Paragraph:bc222b2b2494_36"},{"__ref":"Paragraph:bc222b2b2494_37"},{"__ref":"Paragraph:bc222b2b2494_38"},{"__ref":"Paragraph:bc222b2b2494_39"},{"__ref":"Paragraph:bc222b2b2494_40"},{"__ref":"Paragraph:bc222b2b2494_41"},{"__ref":"Paragraph:bc222b2b2494_42"},{"__ref":"Paragraph:bc222b2b2494_43"},{"__ref":"Paragraph:bc222b2b2494_44"},{"__ref":"Paragraph:bc222b2b2494_45"},{"__ref":"Paragraph:bc222b2b2494_46"},{"__ref":"Paragraph:bc222b2b2494_47"},{"__ref":"Paragraph:bc222b2b2494_48"},{"__ref":"Paragraph:bc222b2b2494_49"},{"__ref":"Paragraph:bc222b2b2494_50"},{"__ref":"Paragraph:bc222b2b2494_51"},{"__ref":"Paragraph:bc222b2b2494_52"},{"__ref":"Paragraph:bc222b2b2494_53"},{"__ref":"Paragraph:bc222b2b2494_54"},{"__ref":"Paragraph:bc222b2b2494_55"},{"__ref":"Paragraph:bc222b2b2494_56"},{"__ref":"Paragraph:bc222b2b2494_57"},{"__ref":"Paragraph:bc222b2b2494_58"},{"__ref":"Paragraph:bc222b2b2494_59"},{"__ref":"Paragraph:bc222b2b2494_60"},{"__ref":"Paragraph:bc222b2b2494_61"},{"__ref":"Paragraph:bc222b2b2494_62"},{"__ref":"Paragraph:bc222b2b2494_63"},{"__ref":"Paragraph:bc222b2b2494_64"},{"__ref":"Paragraph:bc222b2b2494_65"},{"__ref":"Paragraph:bc222b2b2494_66"}]},"validatedShareKey":"","shareKeyCreator":null},"creator":{"__ref":"User:7e94df6b7255"},"inResponseToEntityType":null,"isLocked":false,"isMarkedPaywallOnly":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","mediumUrl":"https:\u002F\u002Fmedium.com\u002F@baptisteloquette.entr\u002Flangchain-arxiv-tutor-data-loading-c62f55af492d","primaryTopic":null,"topics":[{"__typename":"Topic","slug":"machine-learning"},{"__typename":"Topic","slug":"data-science"},{"__typename":"Topic","slug":"programming"}],"isPublished":true,"latestPublishedVersion":"bc222b2b2494","visibility":"PUBLIC","postResponses":{"__typename":"PostResponses","count":3},"createdAt":1688030573341,"firstPublishedAt":1688646530842,"latestPublishedAt":1689576419938,"clapCount":89,"allowResponses":true,"isLimitedState":false,"title":"LangChain Arxiv Tutor : Data Loading","isSeries":false,"sequence":null,"uniqueSlug":"langchain-arxiv-tutor-data-loading-c62f55af492d","socialTitle":"","socialDek":"","noIndex":null,"canonicalUrl":"","metaDescription":"","readingTime":7.270125786163522,"previewContent":{"__typename":"PreviewContent","subtitle":"This Series of Articles covers the usage of LangChain, to create an Arxiv Tutor. That will allow anyone to interact in different ways with…"},"previewImage":{"__ref":"ImageMetadata:1*UpAKNhJYTpaQ4eWJKzWeDQ.png"},"isShortform":false,"seoTitle":"","updatedAt":1692391186769,"shortformType":"SHORTFORM_TYPE_LINK","seoDescription":"","isSuspended":false,"license":"ALL_RIGHTS_RESERVED","tags":[{"__ref":"Tag:llm"},{"__ref":"Tag:chatgpt"},{"__ref":"Tag:gpt"},{"__ref":"Tag:deep-learning"},{"__ref":"Tag:nlp"}],"pendingCollection":null,"statusForCollection":null,"detectedLanguage":"en","wordCount":1825,"layerCake":0}}</script><script>window.__MIDDLEWARE_STATE__={"session":{"xsrf":""},"cache":{"cacheStatus":"EXPIRED"}}</script><script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/manifest.a1038171.js.download"></script><script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/3057.5e22bbb0.js.download"></script><script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/main.95eebc54.js.download"></script><script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/instrumentation.5e7f2981.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/reporting.2021fe63.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/4398.db4d4378.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/7883.0e445e04.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/6733.1d85727b.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/6481.e3e8b67f.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/8695.9065ba3d.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/4341.e697d2a1.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/5971.2c86ab13.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/5203.e7a22052.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/5465.248bcf72.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/6487.d05c271a.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/5459.80a6ee18.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/6804.2cda7ee2.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1711.b70f1a35.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/7652.f5b06845.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/2462.16c628db.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/9174.24f568ee.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/1128.2a9e423b.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/4129.ee8ae2c8.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/8580.feeb2549.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/8883.c8b03d13.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/4078.da7800a7.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/9408.3df4db57.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/9150.42fafb2e.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/5005.b5d4a37c.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/6605.4982ed5d.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/2393.aaa1ee6d.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/2211.706ab0f5.chunk.js.download"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/PostPage.MainContent.c8a337de.chunk.js.download"></script><script>window.main();</script><script defer="" src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/v84a3a4012de94ce1a686ba8c167c359c1696973893317" integrity="sha512-euoFGowhlaLqXsPWQ48qSkBSCFs3DPRyiwVu3FjR96cMPx+Fr+gpWRhIafcHwqwCqWS42RZhIudOvEI+Ckf6MA==" data-cf-beacon="{&quot;rayId&quot;:&quot;864f47bf5f5f8fc6&quot;,&quot;version&quot;:&quot;2024.3.0&quot;,&quot;token&quot;:&quot;0b5f665943484354a59c39c6833f7078&quot;}" crossorigin="anonymous"></script>
<script src="./Data Loading, OCR and Chunking – LangChain Arxiv Tutor _ by Baptiste L. _ Medium_files/client" async=""></script></body></html>